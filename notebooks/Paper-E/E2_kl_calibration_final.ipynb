{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment E2: KL-Controlled Learning\n",
    "\n",
    "**Validation of per-step KL divergence control protocol**\n",
    "\n",
    "---\n",
    "\n",
    "## Generated Files\n",
    "\n",
    "This notebook generates:\n",
    "- `E2_results_full.pkl`\n",
    "- `E2_results_summary.csv`\n",
    "- `E2_gate_validation.csv`\n",
    "- `E2_metadata.json`\n",
    "- `E2_figure.png` (publication quality)\n",
    "- `E2_figure.pdf` (publication quality)\n",
    "\n",
    "**Runtime**: ~10-15 minutes on GPU\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "SAVE_DIR = '/content/drive/MyDrive/paper-E-final/E2'\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "print(f'Results → {SAVE_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gate_a_fisher_quality(fisher, name=\"Fisher\", threshold=-1e-7):\n",
    "    fisher_sym = (fisher + fisher.T) / 2\n",
    "    eigenvalues = torch.linalg.eigvalsh(fisher_sym)\n",
    "    min_eig = eigenvalues.min().item()\n",
    "    max_eig = eigenvalues.max().item()\n",
    "    threshold_value = threshold * abs(max_eig)\n",
    "    details = {\n",
    "        \"min_eigenvalue\": min_eig,\n",
    "        \"max_eigenvalue\": max_eig,\n",
    "        \"condition_number\": max_eig / min_eig if min_eig > 0 else float('inf')\n",
    "    }\n",
    "    if min_eig < threshold_value:\n",
    "        return False, f\"FAIL: {name} negative {min_eig:.2e}\", details\n",
    "    return True, f\"PASS: {name} PSD (min={min_eig:.2e})\", details\n",
    "\n",
    "def gate_b_kl_calibration(kl_measured, kl_target, tolerance=0.2):\n",
    "    ratio = kl_measured / kl_target\n",
    "    lower, upper = 1.0 - tolerance, 1.0 + tolerance\n",
    "    details = {\"kl_measured\": float(kl_measured), \"kl_target\": float(kl_target), \"ratio\": float(ratio)}\n",
    "    if lower <= ratio <= upper:\n",
    "        return True, f\"PASS: ratio={ratio:.4f}\", details\n",
    "    return False, f\"FAIL: ratio={ratio:.4f}\", details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxRegression(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, num_classes, bias=False)\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fisher_analytic(model, X):\n",
    "    with torch.no_grad():\n",
    "        logits = model(X)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        N, C = probs.shape\n",
    "        D = X.shape[1]\n",
    "        fisher = torch.zeros(C * D, C * D, dtype=X.dtype, device=X.device)\n",
    "        for i in range(N):\n",
    "            p = probs[i]\n",
    "            x = X[i]\n",
    "            H = torch.diag(p) - torch.outer(p, p)\n",
    "            F_sample = torch.kron(H, torch.outer(x, x))\n",
    "            fisher += F_sample\n",
    "        fisher /= N\n",
    "        fisher = (fisher + fisher.T) / 2\n",
    "        return fisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n_samples=5000, n_features=16, n_classes=10, noise_std=1.0, seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    centers = torch.randn(n_classes, n_features, dtype=torch.float64)\n",
    "    Q, _ = torch.linalg.qr(centers.T)\n",
    "    centers = (Q[:, :n_classes].T * 2.5).to(device)\n",
    "    samples_per_class = n_samples // n_classes\n",
    "    X_list, y_list = [], []\n",
    "    for c in range(n_classes):\n",
    "        X_class = centers[c] + torch.randn(samples_per_class, n_features, dtype=torch.float64, device=device) * noise_std\n",
    "        y_class = torch.full((samples_per_class,), c, dtype=torch.long, device=device)\n",
    "        X_list.append(X_class)\n",
    "        y_list.append(y_class)\n",
    "    X = torch.cat(X_list)\n",
    "    y = torch.cat(y_list)\n",
    "    perm = torch.randperm(X.shape[0], device=device)\n",
    "    return X[perm], y[perm]\n",
    "\n",
    "X_train, y_train = generate_data(n_samples=5000, seed=42)\n",
    "X_test, y_test = generate_data(n_samples=1000, seed=43)\n",
    "print(f'Data: train={X_train.shape}, test={X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameters_flat(model):\n",
    "    return torch.cat([p.flatten() for p in model.parameters()])\n",
    "\n",
    "def set_parameters_flat(model, params):\n",
    "    offset = 0\n",
    "    for p in model.parameters():\n",
    "        numel = p.numel()\n",
    "        p.data.copy_(params[offset:offset+numel].view_as(p))\n",
    "        offset += numel\n",
    "\n",
    "def compute_empirical_kl(model, X, theta_old):\n",
    "    with torch.no_grad():\n",
    "        theta_new = get_parameters_flat(model).clone()\n",
    "        set_parameters_flat(model, theta_old)\n",
    "        logits_old = model(X)\n",
    "        probs_old = F.softmax(logits_old, dim=1)\n",
    "        set_parameters_flat(model, theta_new)\n",
    "        logits_new = model(X)\n",
    "        probs_new = F.softmax(logits_new, dim=1)\n",
    "        kl = -(probs_old * torch.log(probs_new / (probs_old + 1e-10) + 1e-10)).sum(1).mean()\n",
    "        return kl.item()\n",
    "\n",
    "def evaluate(model, X, y):\n",
    "    with torch.no_grad():\n",
    "        logits = model(X)\n",
    "        loss = F.cross_entropy(logits, y).item()\n",
    "        preds = logits.argmax(dim=1)\n",
    "        acc = (preds == y).float().mean().item()\n",
    "        return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_kl_control(model, X_train, y_train, X_test, y_test, epsilon_step, n_epochs, method='sgd'):\n",
    "    history = {'epoch': [], 'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': [],\n",
    "               'kl_step': [], 'kl_ratio': [], 'eta': [], 'n_corrections': []}\n",
    "    gate_log = []\n",
    "    \n",
    "    fisher = compute_fisher_analytic(model, X_train)\n",
    "    passed_a, msg_a, details_a = gate_a_fisher_quality(fisher)\n",
    "    gate_log.append({'epoch': 0, 'gate': 'A', 'passed': passed_a, **details_a})\n",
    "    if not passed_a:\n",
    "        raise RuntimeError(\"Gate A failed\")\n",
    "    \n",
    "    if method == 'natgrad':\n",
    "        eigvals, eigvecs = torch.linalg.eigh(fisher)\n",
    "        eigvals_inv = torch.where(eigvals > 1e-8, 1.0/eigvals, torch.zeros_like(eigvals))\n",
    "        fisher_inv = eigvecs @ torch.diag(eigvals_inv) @ eigvecs.T\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        theta_old = get_parameters_flat(model).clone()\n",
    "        model.zero_grad()\n",
    "        logits = model(X_train)\n",
    "        loss = F.cross_entropy(logits, y_train)\n",
    "        loss.backward()\n",
    "        grad = torch.cat([p.grad.flatten() for p in model.parameters()])\n",
    "        \n",
    "        if method == 'sgd':\n",
    "            direction = grad\n",
    "            quad_form = torch.dot(direction, fisher @ direction)\n",
    "        else:\n",
    "            direction = fisher_inv @ grad\n",
    "            quad_form = torch.dot(direction, fisher @ direction)\n",
    "        \n",
    "        eta = torch.sqrt(2 * epsilon_step / quad_form)\n",
    "        n_corrections = 0\n",
    "        max_corrections = 2\n",
    "        \n",
    "        while n_corrections <= max_corrections:\n",
    "            theta_new = theta_old - eta * direction\n",
    "            set_parameters_flat(model, theta_new)\n",
    "            kl_emp = compute_empirical_kl(model, X_train, theta_old)\n",
    "            kl_ratio = kl_emp / epsilon_step\n",
    "            if 0.8 <= kl_ratio <= 1.2:\n",
    "                break\n",
    "            eta = eta * torch.sqrt(torch.tensor(epsilon_step / kl_emp))\n",
    "            n_corrections += 1\n",
    "        \n",
    "        train_loss, train_acc = evaluate(model, X_train, y_train)\n",
    "        test_loss, test_acc = evaluate(model, X_test, y_test)\n",
    "        \n",
    "        history['epoch'].append(epoch)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['test_loss'].append(test_loss)\n",
    "        history['test_acc'].append(test_acc)\n",
    "        history['kl_step'].append(kl_emp)\n",
    "        history['kl_ratio'].append(kl_ratio)\n",
    "        history['eta'].append(eta.item())\n",
    "        history['n_corrections'].append(n_corrections)\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            passed_b, msg_b, details_b = gate_b_kl_calibration(kl_emp, epsilon_step)\n",
    "            gate_log.append({'epoch': epoch, 'gate': 'B', 'passed': passed_b, **details_b})\n",
    "    \n",
    "    return history, gate_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'n_features': 16,\n",
    "    'n_classes': 10,\n",
    "    'epsilon_values': [1e-4, 3e-4, 1e-3],\n",
    "    'n_epochs': 100,\n",
    "    'n_seeds': 5,\n",
    "    'methods': ['sgd', 'natgrad']\n",
    "}\n",
    "\n",
    "print(f\"Total experiments: {len(CONFIG['epsilon_values']) * len(CONFIG['methods']) * CONFIG['n_seeds']}\")\n",
    "\n",
    "all_results = {}\n",
    "all_gates = []\n",
    "\n",
    "for eps_idx, epsilon in enumerate(CONFIG['epsilon_values']):\n",
    "    for method in CONFIG['methods']:\n",
    "        for seed in range(CONFIG['n_seeds']):\n",
    "            print(f\"ε={epsilon:.0e}, {method}, seed={seed}\")\n",
    "            set_seed(seed)\n",
    "            model = SoftmaxRegression(CONFIG['n_features'], CONFIG['n_classes']).to(device)\n",
    "            history, gate_log = train_with_kl_control(\n",
    "                model, X_train, y_train, X_test, y_test,\n",
    "                epsilon_step=epsilon, n_epochs=CONFIG['n_epochs'], method=method\n",
    "            )\n",
    "            key = f\"{method}_eps{eps_idx}_seed{seed}\"\n",
    "            all_results[key] = {'method': method, 'epsilon': epsilon, 'seed': seed, 'history': history}\n",
    "            for g in gate_log:\n",
    "                all_gates.append({**g, 'method': method, 'epsilon': epsilon, 'seed': seed})\n",
    "\n",
    "print('✓ Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gate_df = pd.DataFrame(all_gates)\n",
    "gate_a = gate_df[gate_df['gate'] == 'A']\n",
    "gate_b = gate_df[gate_df['gate'] == 'B']\n",
    "print(f\"Gate A: {gate_a['passed'].mean():.1%}\")\n",
    "print(f\"Gate B: {gate_b['passed'].mean():.1%}\")\n",
    "print(f\"Mean KL ratio: {gate_b['ratio'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Publication-quality figure (no title)\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "for i, epsilon in enumerate(CONFIG['epsilon_values']):\n",
    "    ax_curve = axes[0, i]\n",
    "    ax_kl = axes[1, i]\n",
    "    \n",
    "    for method in CONFIG['methods']:\n",
    "        histories = []\n",
    "        for seed in range(CONFIG['n_seeds']):\n",
    "            key = f\"{method}_eps{i}_seed{seed}\"\n",
    "            histories.append(all_results[key]['history'])\n",
    "        \n",
    "        epochs = histories[0]['epoch']\n",
    "        test_accs = np.array([h['test_acc'] for h in histories])\n",
    "        kl_ratios = np.array([h['kl_ratio'] for h in histories])\n",
    "        \n",
    "        mean_acc = test_accs.mean(axis=0)\n",
    "        std_acc = test_accs.std(axis=0)\n",
    "        mean_kl = kl_ratios.mean(axis=0)\n",
    "        std_kl = kl_ratios.std(axis=0)\n",
    "        \n",
    "        label = 'SGD' if method == 'sgd' else 'NG'\n",
    "        ax_curve.plot(epochs, mean_acc, label=label, linewidth=2)\n",
    "        ax_curve.fill_between(epochs, mean_acc - std_acc, mean_acc + std_acc, alpha=0.2)\n",
    "        ax_kl.plot(epochs, mean_kl, label=label, linewidth=2)\n",
    "        ax_kl.fill_between(epochs, mean_kl - std_kl, mean_kl + std_kl, alpha=0.2)\n",
    "    \n",
    "    ax_curve.set_xlabel('Epoch', fontsize=10)\n",
    "    if i == 0:\n",
    "        ax_curve.set_ylabel('Test Accuracy', fontsize=10)\n",
    "    ax_curve.legend(fontsize=9)\n",
    "    ax_curve.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax_kl.axhline(y=1.0, color='red', linestyle='--', alpha=0.5)\n",
    "    ax_kl.axhline(y=0.8, color='gray', linestyle=':', alpha=0.3)\n",
    "    ax_kl.axhline(y=1.2, color='gray', linestyle=':', alpha=0.3)\n",
    "    ax_kl.set_xlabel('Epoch', fontsize=10)\n",
    "    if i == 0:\n",
    "        ax_kl.set_ylabel('KL Ratio', fontsize=10)\n",
    "    ax_kl.legend(fontsize=9)\n",
    "    ax_kl.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{SAVE_DIR}/E2_figure.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig(f'{SAVE_DIR}/E2_figure.pdf', bbox_inches='tight')\n",
    "print('Figure saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{SAVE_DIR}/E2_results_full.pkl', 'wb') as f:\n",
    "    pickle.dump(all_results, f)\n",
    "\n",
    "summary_records = []\n",
    "for key, data in all_results.items():\n",
    "    hist = data['history']\n",
    "    summary_records.append({\n",
    "        'method': data['method'], 'epsilon': data['epsilon'], 'seed': data['seed'],\n",
    "        'final_loss': hist['train_loss'][-1], 'final_accuracy': hist['test_acc'][-1],\n",
    "        'mean_kl_ratio': np.mean(hist['kl_ratio']), 'std_kl_ratio': np.std(hist['kl_ratio']),\n",
    "        'mean_corrections': np.mean(hist['n_corrections'])\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_records)\n",
    "summary_df.to_csv(f'{SAVE_DIR}/E2_results_summary.csv', index=False)\n",
    "gate_df.to_csv(f'{SAVE_DIR}/E2_gate_validation.csv', index=False)\n",
    "\n",
    "metadata = {\n",
    "    'experiment': 'E2',\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'config': CONFIG,\n",
    "    'gate_summary': {\n",
    "        'gate_a_pass_rate': float(gate_a['passed'].mean()),\n",
    "        'gate_b_pass_rate': float(gate_b['passed'].mean()),\n",
    "        'mean_kl_ratio': float(gate_b['ratio'].mean())\n",
    "    },\n",
    "    'performance_summary': {\n",
    "        'sgd_mean_accuracy': float(summary_df[summary_df['method']=='sgd']['final_accuracy'].mean()),\n",
    "        'ng_mean_accuracy': float(summary_df[summary_df['method']=='natgrad']['final_accuracy'].mean())\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(f'{SAVE_DIR}/E2_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f'\\n✓ All files saved to {SAVE_DIR}')\n",
    "print('  - E2_results_full.pkl')\n",
    "print('  - E2_results_summary.csv')\n",
    "print('  - E2_gate_validation.csv')\n",
    "print('  - E2_metadata.json')\n",
    "print('  - E2_figure.png')\n",
    "print('  - E2_figure.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
