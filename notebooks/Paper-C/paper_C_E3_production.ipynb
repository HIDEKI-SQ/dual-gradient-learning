{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper C - Experiment E3: Learning Demo (本番)\n",
    "\n",
    "## 較正済み設定\n",
    "- **center_scale = 2.5**\n",
    "- **noise_std = 1.0**\n",
    "- SNR = 2.5\n",
    "- Clean training test accuracy: 79.9% (in 70-85% target)\n",
    "\n",
    "## 実験設計\n",
    "- Noise levels: 0%, 30%, 50% (3水準)\n",
    "- ρ: -0.7, -0.4, -0.2, 0.0, +0.4, +0.7, +1.0 (7水準)\n",
    "- λ: 0.00, 0.25, 0.50, 0.75, 1.00 (5水準)\n",
    "- Seeds: 10\n",
    "- **Total: 1,050 runs**\n",
    "\n",
    "## 出力\n",
    "- Fig C5: Accuracy surface (ρ × λ)\n",
    "- Fig C6: Effect of ρ at different λ\n",
    "- Fig C7: cos(g_val, g_ref) verification\n",
    "- Fig C8: Confounding visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "SAVE_DIR = '/content/drive/MyDrive/paper-C-results/E3_production'\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "print(f'Save directory: {SAVE_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "print(f'Started: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 較正済み設定\n",
    "# ========================================\n",
    "\n",
    "# データ生成パラメータ（較正済み）\n",
    "CENTER_SCALE = 2.5  # ★ 較正済み\n",
    "NOISE_STD_DATA = 1.0  # ★ 較正済み\n",
    "N_TRAIN = 20000\n",
    "N_TEST = 10000\n",
    "N_CLASSES = 10\n",
    "DIM_PER_VIEW = 8\n",
    "CENTER_SEED = 0\n",
    "\n",
    "# 実験グリッド\n",
    "NOISE_RATES = [0.0, 0.3, 0.5]  # ラベルノイズ率\n",
    "RHO_VALUES = [-0.7, -0.4, -0.2, 0.0, 0.4, 0.7, 1.0]\n",
    "LAMBDA_VALUES = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "SEEDS = list(range(10))\n",
    "\n",
    "# 学習パラメータ\n",
    "EPOCHS = 100\n",
    "LR = 0.1\n",
    "\n",
    "TOTAL_RUNS = len(NOISE_RATES) * len(RHO_VALUES) * len(LAMBDA_VALUES) * len(SEEDS)\n",
    "\n",
    "print('=' * 60)\n",
    "print('E3 Production: Learning Demo')\n",
    "print('=' * 60)\n",
    "print(f'\\n■ 較正済み設定:')\n",
    "print(f'  center_scale = {CENTER_SCALE}')\n",
    "print(f'  noise_std = {NOISE_STD_DATA}')\n",
    "print(f'  Expected clean accuracy: ~80%')\n",
    "print(f'\\n■ 実験グリッド:')\n",
    "print(f'  Noise rates: {NOISE_RATES}')\n",
    "print(f'  ρ values: {RHO_VALUES}')\n",
    "print(f'  λ values: {LAMBDA_VALUES}')\n",
    "print(f'  Seeds: {len(SEEDS)}')\n",
    "print(f'\\n■ Total runs: {TOTAL_RUNS}')\n",
    "print('=' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ生成関数\n",
    "\n",
    "def generate_orthogonal_centers(n_classes, dim_per_view, center_scale, seed=0):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    total_dim = dim_per_view * 2\n",
    "    random_matrix = rng.randn(total_dim, n_classes)\n",
    "    Q, _ = np.linalg.qr(random_matrix)\n",
    "    centers_joint = Q[:, :n_classes].T * center_scale\n",
    "    centers_A = centers_joint[:, :dim_per_view]\n",
    "    centers_B = centers_joint[:, dim_per_view:]\n",
    "    return centers_A.astype(np.float32), centers_B.astype(np.float32)\n",
    "\n",
    "def generate_two_view_data(n_samples, centers_A, centers_B, noise_std, sample_seed):\n",
    "    n_classes = centers_A.shape[0]\n",
    "    dim_per_view = centers_A.shape[1]\n",
    "    rng = np.random.RandomState(sample_seed)\n",
    "    labels = rng.randint(0, n_classes, n_samples)\n",
    "    view_A = np.array([centers_A[l] + rng.randn(dim_per_view) * noise_std for l in labels])\n",
    "    view_B = np.array([centers_B[l] + rng.randn(dim_per_view) * noise_std for l in labels])\n",
    "    X = np.concatenate([view_A, view_B], axis=1)\n",
    "    return X.astype(np.float32), labels.astype(np.int64)\n",
    "\n",
    "def inject_label_noise(labels, noise_rate, n_classes=10, seed=42):\n",
    "    if noise_rate == 0:\n",
    "        return labels.copy()\n",
    "    rng = np.random.RandomState(seed + 1000)\n",
    "    noisy = labels.copy()\n",
    "    n_noisy = int(noise_rate * len(labels))\n",
    "    indices = rng.choice(len(labels), n_noisy, replace=False)\n",
    "    for idx in indices:\n",
    "        noisy[idx] = rng.choice([i for i in range(n_classes) if i != labels[idx]])\n",
    "    return noisy\n",
    "\n",
    "print('データ生成関数定義完了')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル定義\n",
    "\n",
    "class TwoViewMLP(nn.Module):\n",
    "    def __init__(self, input_dim=16, hidden_dim=64, n_classes=10):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, n_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "print('モデル定義完了')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 勾配操作関数\n",
    "\n",
    "def get_gradient_vector(model):\n",
    "    \"\"\"モデルの全パラメータの勾配を1つのベクトルとして取得\"\"\"\n",
    "    grads = []\n",
    "    for p in model.parameters():\n",
    "        if p.grad is not None:\n",
    "            grads.append(p.grad.view(-1))\n",
    "    return torch.cat(grads)\n",
    "\n",
    "def set_gradient_vector(model, grad_vec):\n",
    "    \"\"\"ベクトルをモデルの各パラメータの勾配として設定\"\"\"\n",
    "    idx = 0\n",
    "    for p in model.parameters():\n",
    "        numel = p.numel()\n",
    "        p.grad = grad_vec[idx:idx+numel].view(p.shape).clone()\n",
    "        idx += numel\n",
    "\n",
    "def orthogonalize(g_ref_norm, v):\n",
    "    \"\"\"vからg_ref_norm方向の成分を除去し、正規化\"\"\"\n",
    "    v_perp = v - torch.dot(v, g_ref_norm) * g_ref_norm\n",
    "    norm = torch.norm(v_perp)\n",
    "    if norm < 1e-10:\n",
    "        # 万が一平行な場合はランダムベクトルで再試行\n",
    "        v = torch.randn_like(v)\n",
    "        v_perp = v - torch.dot(v, g_ref_norm) * g_ref_norm\n",
    "        norm = torch.norm(v_perp)\n",
    "    return v_perp / norm\n",
    "\n",
    "def construct_g_value(g_ref_norm, rho, device):\n",
    "    \"\"\"\n",
    "    ρ-design: cos(g_value, g_ref) = ρ となるg_valueを構築\n",
    "    g_value = ρ * g_ref_norm + sqrt(1-ρ²) * g_perp\n",
    "    \"\"\"\n",
    "    # g_refに直交するランダムベクトルを生成\n",
    "    random_vec = torch.randn_like(g_ref_norm)\n",
    "    g_perp = orthogonalize(g_ref_norm, random_vec)\n",
    "    \n",
    "    # ρに基づいてg_valueを構築\n",
    "    if abs(rho) >= 1.0:\n",
    "        g_value = rho * g_ref_norm\n",
    "    else:\n",
    "        sqrt_term = np.sqrt(1 - rho**2)\n",
    "        g_value = rho * g_ref_norm + sqrt_term * g_perp\n",
    "    \n",
    "    # 正規化\n",
    "    g_value = g_value / torch.norm(g_value)\n",
    "    return g_value, g_perp\n",
    "\n",
    "print('勾配操作関数定義完了')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実験実行関数\n",
    "\n",
    "def run_experiment(noise_rate, rho, lam, model_seed):\n",
    "    \"\"\"\n",
    "    1つの(noise_rate, ρ, λ, seed)設定で学習を実行\n",
    "    \n",
    "    Returns:\n",
    "        dict: 結果（accuracy, cos値など）\n",
    "    \"\"\"\n",
    "    # クラス中心を生成（固定）\n",
    "    centers_A, centers_B = generate_orthogonal_centers(\n",
    "        N_CLASSES, DIM_PER_VIEW, CENTER_SCALE, seed=CENTER_SEED\n",
    "    )\n",
    "    \n",
    "    # データ生成\n",
    "    X_train, y_train_clean = generate_two_view_data(\n",
    "        N_TRAIN, centers_A, centers_B, NOISE_STD_DATA, sample_seed=42\n",
    "    )\n",
    "    X_test, y_test = generate_two_view_data(\n",
    "        N_TEST, centers_A, centers_B, NOISE_STD_DATA, sample_seed=43\n",
    "    )\n",
    "    \n",
    "    # ラベルノイズ注入\n",
    "    y_train_noisy = inject_label_noise(y_train_clean, noise_rate, N_CLASSES, seed=model_seed)\n",
    "    \n",
    "    # テンソル化\n",
    "    X_train_t = torch.tensor(X_train, device=device)\n",
    "    y_clean_t = torch.tensor(y_train_clean, device=device)\n",
    "    y_noisy_t = torch.tensor(y_train_noisy, device=device)\n",
    "    X_test_t = torch.tensor(X_test, device=device)\n",
    "    y_test_t = torch.tensor(y_test, device=device)\n",
    "    \n",
    "    # モデル初期化\n",
    "    set_seed(model_seed)\n",
    "    model = TwoViewMLP().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # cos値の記録用\n",
    "    cos_values = []\n",
    "    \n",
    "    # 学習ループ\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        \n",
    "        # Step 1: g_ref（clean labels）の計算\n",
    "        optimizer.zero_grad()\n",
    "        loss_ref = criterion(model(X_train_t), y_clean_t)\n",
    "        loss_ref.backward()\n",
    "        g_ref = get_gradient_vector(model).clone()\n",
    "        g_ref_norm = g_ref / torch.norm(g_ref)\n",
    "        g_ref_scale = torch.norm(g_ref)  # 元のスケールを保存\n",
    "        \n",
    "        # Step 2: g_struct（noisy labels）の計算\n",
    "        optimizer.zero_grad()\n",
    "        loss_struct = criterion(model(X_train_t), y_noisy_t)\n",
    "        loss_struct.backward()\n",
    "        g_struct = get_gradient_vector(model).clone()\n",
    "        g_struct_norm = g_struct / torch.norm(g_struct)\n",
    "        g_struct_scale = torch.norm(g_struct)\n",
    "        \n",
    "        # Step 3: g_value（ρ-design）の構築\n",
    "        g_value, _ = construct_g_value(g_ref_norm, rho, device)\n",
    "        \n",
    "        # cos検証（記録用）\n",
    "        cos_actual = torch.dot(g_value, g_ref_norm).item()\n",
    "        cos_values.append(cos_actual)\n",
    "        \n",
    "        # Step 4: 勾配の混合 g_mix = λ * g_struct + (1-λ) * g_value\n",
    "        g_mix = lam * g_struct_norm + (1 - lam) * g_value\n",
    "        g_mix = g_mix / torch.norm(g_mix)  # 正規化\n",
    "        \n",
    "        # スケール復元（g_structのスケールを使用）\n",
    "        g_mix_scaled = g_mix * g_struct_scale\n",
    "        \n",
    "        # Step 5: 勾配を設定して更新\n",
    "        optimizer.zero_grad()\n",
    "        set_gradient_vector(model, g_mix_scaled)\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 評価\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_acc = (model(X_train_t).argmax(1) == y_clean_t).float().mean().item()\n",
    "        test_acc = (model(X_test_t).argmax(1) == y_test_t).float().mean().item()\n",
    "    \n",
    "    return {\n",
    "        'noise_rate': noise_rate,\n",
    "        'rho': rho,\n",
    "        'lambda': lam,\n",
    "        'seed': model_seed,\n",
    "        'train_acc': train_acc,\n",
    "        'test_acc': test_acc,\n",
    "        'cos_mean': np.mean(cos_values),\n",
    "        'cos_std': np.std(cos_values),\n",
    "        'cos_final': cos_values[-1] if cos_values else 0\n",
    "    }\n",
    "\n",
    "print('実験実行関数定義完了')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ★ 動作確認（1設定）\n",
    "\n",
    "print('=== 動作確認 ===')\n",
    "result = run_experiment(noise_rate=0.3, rho=0.7, lam=0.5, model_seed=0)\n",
    "print(f'noise=30%, ρ=0.7, λ=0.5')\n",
    "print(f'  test_acc = {result[\"test_acc\"]:.3f}')\n",
    "print(f'  cos(g_val, g_ref) = {result[\"cos_mean\"]:.4f} (target: 0.7)')\n",
    "\n",
    "if abs(result['cos_mean'] - 0.7) < 0.05:\n",
    "    print('\\n✓ ρ-design検証OK')\n",
    "else:\n",
    "    print('\\n⚠️ cos値がターゲットからずれています')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 本番実験の実行\n",
    "# ========================================\n",
    "\n",
    "print('\\n' + '=' * 60)\n",
    "print('E3 Production: Main Experiment')\n",
    "print(f'Total: {TOTAL_RUNS} runs')\n",
    "print('=' * 60 + '\\n')\n",
    "\n",
    "results = []\n",
    "start_time = time.time()\n",
    "run_count = 0\n",
    "\n",
    "for noise_rate in NOISE_RATES:\n",
    "    noise_pct = int(noise_rate * 100)\n",
    "    print(f'\\n=== NOISE {noise_pct}% ===')\n",
    "    \n",
    "    for rho in RHO_VALUES:\n",
    "        for lam in LAMBDA_VALUES:\n",
    "            for seed in SEEDS:\n",
    "                run_count += 1\n",
    "                result = run_experiment(noise_rate, rho, lam, seed)\n",
    "                results.append(result)\n",
    "                \n",
    "                # 進捗表示（50回ごと）\n",
    "                if run_count % 50 == 0:\n",
    "                    elapsed = time.time() - start_time\n",
    "                    eta = elapsed / run_count * (TOTAL_RUNS - run_count)\n",
    "                    print(f'  [{run_count:4d}/{TOTAL_RUNS}] '\n",
    "                          f'noise={noise_pct}% ρ={rho:+.1f} λ={lam:.2f} | '\n",
    "                          f'acc={result[\"test_acc\"]:.3f} | '\n",
    "                          f'ETA: {eta/60:.1f}min')\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f'\\n' + '=' * 60)\n",
    "print(f'完了！ Total time: {total_time/60:.1f} min')\n",
    "print('=' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果をDataFrameに変換\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# 集計（seed平均）\n",
    "df_agg = df.groupby(['noise_rate', 'rho', 'lambda']).agg({\n",
    "    'train_acc': ['mean', 'std'],\n",
    "    'test_acc': ['mean', 'std'],\n",
    "    'cos_mean': ['mean', 'std']\n",
    "}).reset_index()\n",
    "df_agg.columns = ['noise_rate', 'rho', 'lambda', \n",
    "                  'train_acc_mean', 'train_acc_std',\n",
    "                  'test_acc_mean', 'test_acc_std',\n",
    "                  'cos_mean', 'cos_std']\n",
    "\n",
    "print('結果集計完了')\n",
    "print(f'総レコード数: {len(df)}')\n",
    "print(f'集計後レコード数: {len(df_agg)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig C5: Accuracy Surface (ρ × λ)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for idx, noise_rate in enumerate(NOISE_RATES):\n",
    "    ax = axes[idx]\n",
    "    noise_pct = int(noise_rate * 100)\n",
    "    \n",
    "    df_noise = df_agg[df_agg['noise_rate'] == noise_rate]\n",
    "    pivot = df_noise.pivot(index='rho', columns='lambda', values='test_acc_mean')\n",
    "    \n",
    "    im = ax.imshow(pivot.values, cmap='RdYlGn', aspect='auto', \n",
    "                   vmin=0.1, vmax=1.0, origin='lower')\n",
    "    \n",
    "    ax.set_xticks(range(len(LAMBDA_VALUES)))\n",
    "    ax.set_xticklabels([f'{l:.2f}' for l in LAMBDA_VALUES])\n",
    "    ax.set_yticks(range(len(RHO_VALUES)))\n",
    "    ax.set_yticklabels([f'{r:+.1f}' for r in RHO_VALUES])\n",
    "    ax.set_xlabel('λ', fontsize=12)\n",
    "    ax.set_ylabel('ρ', fontsize=12)\n",
    "    ax.set_title(f'Noise = {noise_pct}%', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 値を表示\n",
    "    for i in range(len(RHO_VALUES)):\n",
    "        for j in range(len(LAMBDA_VALUES)):\n",
    "            val = pivot.values[i, j]\n",
    "            color = 'white' if val < 0.5 else 'black'\n",
    "            ax.text(j, i, f'{val:.2f}', ha='center', va='center', \n",
    "                   fontsize=8, color=color)\n",
    "\n",
    "plt.colorbar(im, ax=axes, label='Test Accuracy', shrink=0.8)\n",
    "fig.suptitle('Fig C5: Accuracy Surface', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{SAVE_DIR}/fig_C5_accuracy_surface.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('✓ Fig C5 保存完了')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig C6: Effect of ρ at Different λ\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(LAMBDA_VALUES)))\n",
    "\n",
    "for idx, noise_rate in enumerate(NOISE_RATES):\n",
    "    ax = axes[idx]\n",
    "    noise_pct = int(noise_rate * 100)\n",
    "    \n",
    "    df_noise = df_agg[df_agg['noise_rate'] == noise_rate]\n",
    "    \n",
    "    for lam_idx, lam in enumerate(LAMBDA_VALUES):\n",
    "        df_lam = df_noise[df_noise['lambda'] == lam]\n",
    "        ax.errorbar(df_lam['rho'], df_lam['test_acc_mean'], \n",
    "                   yerr=df_lam['test_acc_std'],\n",
    "                   marker='o', label=f'λ={lam:.2f}', \n",
    "                   color=colors[lam_idx], capsize=3)\n",
    "    \n",
    "    ax.axhline(y=0.1, color='red', linestyle='--', alpha=0.5, label='Chance')\n",
    "    ax.set_xlabel('ρ', fontsize=12)\n",
    "    ax.set_ylabel('Test Accuracy', fontsize=12)\n",
    "    ax.set_title(f'Noise = {noise_pct}%', fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='best', fontsize=8)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "fig.suptitle('Fig C6: Effect of ρ at Different λ', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{SAVE_DIR}/fig_C6_rho_effect.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('✓ Fig C6 保存完了')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig C7: cos(g_val, g_ref) Verification\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# ρごとに集計\n",
    "df_cos = df.groupby('rho')['cos_mean'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "ax.errorbar(df_cos['rho'], df_cos['mean'], yerr=df_cos['std'],\n",
    "           marker='o', markersize=10, capsize=5, linewidth=2, label='Measured')\n",
    "\n",
    "# 理想線\n",
    "ax.plot(RHO_VALUES, RHO_VALUES, 'r--', linewidth=2, label='Ideal (cos = ρ)')\n",
    "\n",
    "ax.set_xlabel('Target ρ', fontsize=14)\n",
    "ax.set_ylabel('Measured cos(g_val, g_ref)', fontsize=14)\n",
    "ax.set_title('Fig C7: ρ-Design Verification', fontsize=16, fontweight='bold')\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xlim(-1, 1.1)\n",
    "ax.set_ylim(-1, 1.1)\n",
    "\n",
    "# 誤差統計を表示\n",
    "cos_deviation = np.abs(df_cos['mean'].values - df_cos['rho'].values)\n",
    "ax.text(0.05, 0.95, f'Max deviation: {cos_deviation.max():.6f}',\n",
    "       transform=ax.transAxes, fontsize=10, verticalalignment='top',\n",
    "       bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{SAVE_DIR}/fig_C7_cos_verification.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('✓ Fig C7 保存完了')\n",
    "print(f'  cos検証: max deviation = {cos_deviation.max():.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig C8: Confounding Visualization\n",
    "# A_naive = cos(g_mix, g_ref) がλで変動することを示す\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for idx, noise_rate in enumerate(NOISE_RATES):\n",
    "    ax = axes[idx]\n",
    "    noise_pct = int(noise_rate * 100)\n",
    "    \n",
    "    df_noise = df_agg[df_agg['noise_rate'] == noise_rate]\n",
    "    \n",
    "    # ρを固定してλによるcos_mean（≈A_naive）の変動を見る\n",
    "    for rho in [0.0, 0.4, 0.7, 1.0]:\n",
    "        df_rho = df_noise[df_noise['rho'] == rho]\n",
    "        if len(df_rho) > 0:\n",
    "            ax.plot(df_rho['lambda'], df_rho['test_acc_mean'], \n",
    "                   marker='o', label=f'ρ={rho:+.1f}')\n",
    "    \n",
    "    ax.set_xlabel('λ', fontsize=12)\n",
    "    ax.set_ylabel('Test Accuracy', fontsize=12)\n",
    "    ax.set_title(f'Noise = {noise_pct}%', fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='best', fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "fig.suptitle('Fig C8: Effect of λ at Fixed ρ (Confounding Check)', \n",
    "            fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{SAVE_DIR}/fig_C8_confounding.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('✓ Fig C8 保存完了')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果の保存\n",
    "\n",
    "# 生データ\n",
    "df.to_csv(f'{SAVE_DIR}/E3_results_raw.csv', index=False)\n",
    "\n",
    "# 集計データ\n",
    "df_agg.to_csv(f'{SAVE_DIR}/E3_results_aggregated.csv', index=False)\n",
    "\n",
    "# サマリーJSON\n",
    "summary = {\n",
    "    'experiment': 'E3_production',\n",
    "    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'calibrated_settings': {\n",
    "        'center_scale': CENTER_SCALE,\n",
    "        'noise_std': NOISE_STD_DATA,\n",
    "        'snr': CENTER_SCALE / NOISE_STD_DATA\n",
    "    },\n",
    "    'grid': {\n",
    "        'noise_rates': NOISE_RATES,\n",
    "        'rho_values': RHO_VALUES,\n",
    "        'lambda_values': LAMBDA_VALUES,\n",
    "        'n_seeds': len(SEEDS)\n",
    "    },\n",
    "    'total_runs': TOTAL_RUNS,\n",
    "    'cos_verification': {\n",
    "        'max_deviation': float(cos_deviation.max()),\n",
    "        'mean_deviation': float(cos_deviation.mean())\n",
    "    },\n",
    "    'accuracy_summary': {\n",
    "        'overall_mean': float(df['test_acc'].mean()),\n",
    "        'overall_std': float(df['test_acc'].std()),\n",
    "        'by_noise': {f'{int(nr*100)}%': float(df[df['noise_rate']==nr]['test_acc'].mean()) \n",
    "                    for nr in NOISE_RATES}\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(f'{SAVE_DIR}/E3_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print('\\n=== 保存完了 ===')\n",
    "print(f'  {SAVE_DIR}/E3_results_raw.csv')\n",
    "print(f'  {SAVE_DIR}/E3_results_aggregated.csv')\n",
    "print(f'  {SAVE_DIR}/E3_summary.json')\n",
    "print(f'  {SAVE_DIR}/fig_C5_accuracy_surface.png')\n",
    "print(f'  {SAVE_DIR}/fig_C6_rho_effect.png')\n",
    "print(f'  {SAVE_DIR}/fig_C7_cos_verification.png')\n",
    "print(f'  {SAVE_DIR}/fig_C8_confounding.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最終サマリー\n",
    "\n",
    "print('\\n' + '=' * 70)\n",
    "print('E3 Production 完了')\n",
    "print('=' * 70)\n",
    "\n",
    "print('\\n■ 較正済み設定:')\n",
    "print(f'  center_scale = {CENTER_SCALE}')\n",
    "print(f'  noise_std = {NOISE_STD_DATA}')\n",
    "print(f'  SNR = {CENTER_SCALE / NOISE_STD_DATA}')\n",
    "\n",
    "print('\\n■ ρ-design検証:')\n",
    "print(f'  cos(g_val, g_ref) = ρ')\n",
    "print(f'  Max deviation: {cos_deviation.max():.6f}')\n",
    "\n",
    "print('\\n■ 精度サマリー:')\n",
    "for noise_rate in NOISE_RATES:\n",
    "    noise_pct = int(noise_rate * 100)\n",
    "    mean_acc = df[df['noise_rate'] == noise_rate]['test_acc'].mean()\n",
    "    std_acc = df[df['noise_rate'] == noise_rate]['test_acc'].std()\n",
    "    print(f'  Noise {noise_pct}%: {mean_acc:.1%} ± {std_acc:.1%}')\n",
    "\n",
    "print('\\n■ 出力ファイル:')\n",
    "print('  - Fig C5: Accuracy Surface')\n",
    "print('  - Fig C6: Effect of ρ at Different λ')\n",
    "print('  - Fig C7: cos Verification')\n",
    "print('  - Fig C8: Confounding Check')\n",
    "\n",
    "print('\\n' + '=' * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
