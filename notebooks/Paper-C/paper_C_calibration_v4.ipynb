{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper C - 較正実験 (Calibration) v4\n",
    "\n",
    "## v4での修正\n",
    "- **SNR範囲を下げる**：v3では課題が簡単すぎた（全設定で100%）\n",
    "- center_scale: 5-15 → **1-3**\n",
    "- noise_std: 0.25-0.50 → **1.0-3.0**\n",
    "- これによりSNR = 0.33〜3.0の範囲で探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "SAVE_DIR = '/content/drive/MyDrive/paper-C-results/calibration_v4'\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "print(f'Save directory: {SAVE_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ生成関数（v3と同じ）\n",
    "\n",
    "def generate_orthogonal_centers(n_classes, dim_per_view, center_scale, seed=0):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    total_dim = dim_per_view * 2\n",
    "    \n",
    "    random_matrix = rng.randn(total_dim, n_classes)\n",
    "    Q, _ = np.linalg.qr(random_matrix)\n",
    "    centers_joint = Q[:, :n_classes].T * center_scale\n",
    "    \n",
    "    centers_A = centers_joint[:, :dim_per_view]\n",
    "    centers_B = centers_joint[:, dim_per_view:]\n",
    "    \n",
    "    return centers_A.astype(np.float32), centers_B.astype(np.float32)\n",
    "\n",
    "def generate_two_view_data(n_samples, centers_A, centers_B, noise_std, sample_seed):\n",
    "    n_classes = centers_A.shape[0]\n",
    "    dim_per_view = centers_A.shape[1]\n",
    "    \n",
    "    rng = np.random.RandomState(sample_seed)\n",
    "    labels = rng.randint(0, n_classes, n_samples)\n",
    "    \n",
    "    view_A = np.array([centers_A[l] + rng.randn(dim_per_view) * noise_std for l in labels])\n",
    "    view_B = np.array([centers_B[l] + rng.randn(dim_per_view) * noise_std for l in labels])\n",
    "    \n",
    "    X = np.concatenate([view_A, view_B], axis=1)\n",
    "    return X.astype(np.float32), labels.astype(np.int64)\n",
    "\n",
    "print('データ生成関数定義完了')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル定義\n",
    "\n",
    "class TwoViewMLP(nn.Module):\n",
    "    def __init__(self, input_dim=16, hidden_dim=64, n_classes=10):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, n_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "print('モデル定義完了')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ★★★ v4: SNR範囲を調整 ★★★\n",
    "\n",
    "N_TRAIN = 20000\n",
    "N_TEST = 10000\n",
    "N_CLASSES = 10\n",
    "DIM_PER_VIEW = 8\n",
    "\n",
    "# v4: 課題を難しくする\n",
    "CENTER_SCALES = [1.0, 1.5, 2.0, 2.5, 3.0]  # 小さく\n",
    "NOISE_STDS = [1.0, 1.5, 2.0, 2.5, 3.0]     # 大きく\n",
    "\n",
    "EPOCHS = 100\n",
    "LR = 0.1\n",
    "SEEDS = [0, 1, 2]\n",
    "\n",
    "CENTER_SEED = 0\n",
    "TRAIN_SAMPLE_SEED = 42\n",
    "TEST_SAMPLE_SEED = 43\n",
    "\n",
    "TARGET_ACC_MIN = 0.70\n",
    "TARGET_ACC_MAX = 0.85\n",
    "\n",
    "# SNR範囲を計算して表示\n",
    "snr_min = min(CENTER_SCALES) / max(NOISE_STDS)\n",
    "snr_max = max(CENTER_SCALES) / min(NOISE_STDS)\n",
    "\n",
    "print(f'=== 較正実験設定 (v4) ===')\n",
    "print(f'★ v4修正: SNR範囲を下げる（課題を難しくする）')\n",
    "print(f'  center_scale: {CENTER_SCALES}')\n",
    "print(f'  noise_std: {NOISE_STDS}')\n",
    "print(f'  SNR範囲: {snr_min:.2f} - {snr_max:.2f}')\n",
    "print(f'\\nデータ: train={N_TRAIN}, test={N_TEST}')\n",
    "print(f'ターゲット精度: {TARGET_ACC_MIN*100:.0f}% - {TARGET_ACC_MAX*100:.0f}%')\n",
    "print(f'総実験数: {len(CENTER_SCALES) * len(NOISE_STDS) * len(SEEDS)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 較正実験の実行関数\n",
    "\n",
    "def run_calibration_trial(center_scale, noise_std, model_seed):\n",
    "    centers_A, centers_B = generate_orthogonal_centers(\n",
    "        N_CLASSES, DIM_PER_VIEW, center_scale, seed=CENTER_SEED\n",
    "    )\n",
    "    \n",
    "    X_train, y_train = generate_two_view_data(\n",
    "        N_TRAIN, centers_A, centers_B, noise_std, sample_seed=TRAIN_SAMPLE_SEED\n",
    "    )\n",
    "    X_test, y_test = generate_two_view_data(\n",
    "        N_TEST, centers_A, centers_B, noise_std, sample_seed=TEST_SAMPLE_SEED\n",
    "    )\n",
    "    \n",
    "    X_train_t = torch.tensor(X_train, device=device)\n",
    "    y_train_t = torch.tensor(y_train, device=device)\n",
    "    X_test_t = torch.tensor(X_test, device=device)\n",
    "    y_test_t = torch.tensor(y_test, device=device)\n",
    "    \n",
    "    set_seed(model_seed)\n",
    "    model = TwoViewMLP().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(X_train_t), y_train_t)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_acc = (model(X_train_t).argmax(1) == y_train_t).float().mean().item()\n",
    "        test_acc = (model(X_test_t).argmax(1) == y_test_t).float().mean().item()\n",
    "    \n",
    "    return train_acc, test_acc\n",
    "\n",
    "print('較正実験関数定義完了')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 動作確認（中間的なSNRで）\n",
    "\n",
    "print('=== 動作確認 ===')\n",
    "for cs, ns in [(3.0, 1.0), (2.0, 2.0), (1.0, 3.0)]:\n",
    "    snr = cs / ns\n",
    "    train_acc, test_acc = run_calibration_trial(cs, ns, model_seed=0)\n",
    "    print(f'scale={cs}, noise={ns} (SNR={snr:.2f}) | train={train_acc:.3f}, test={test_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 較正実験の実行\n",
    "\n",
    "print('\\n=== 較正実験開始 ===')\n",
    "print(f'ターゲット: test accuracy {TARGET_ACC_MIN*100:.0f}%-{TARGET_ACC_MAX*100:.0f}%')\n",
    "print('-' * 70)\n",
    "\n",
    "results = []\n",
    "total = len(CENTER_SCALES) * len(NOISE_STDS) * len(SEEDS)\n",
    "run_count = 0\n",
    "\n",
    "for center_scale in CENTER_SCALES:\n",
    "    for noise_std in NOISE_STDS:\n",
    "        seed_results = []\n",
    "        \n",
    "        for seed in SEEDS:\n",
    "            run_count += 1\n",
    "            train_acc, test_acc = run_calibration_trial(center_scale, noise_std, seed)\n",
    "            seed_results.append({'train': train_acc, 'test': test_acc})\n",
    "        \n",
    "        mean_train = np.mean([r['train'] for r in seed_results])\n",
    "        mean_test = np.mean([r['test'] for r in seed_results])\n",
    "        std_test = np.std([r['test'] for r in seed_results])\n",
    "        snr = center_scale / noise_std\n",
    "        \n",
    "        in_target = TARGET_ACC_MIN <= mean_test <= TARGET_ACC_MAX\n",
    "        marker = '★' if in_target else ''\n",
    "        \n",
    "        results.append({\n",
    "            'center_scale': center_scale,\n",
    "            'noise_std': noise_std,\n",
    "            'snr': snr,\n",
    "            'train_acc': mean_train,\n",
    "            'test_acc': mean_test,\n",
    "            'test_std': std_test,\n",
    "            'in_target': in_target\n",
    "        })\n",
    "        \n",
    "        print(f'[{run_count:3d}/{total}] scale={center_scale:.1f}, noise={noise_std:.1f} (SNR={snr:.2f}) | '\n",
    "              f'train={mean_train:.3f}, test={mean_test:.3f}±{std_test:.3f} {marker}')\n",
    "\n",
    "print('-' * 70)\n",
    "print('較正実験完了')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果の整理\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df_target = df[df['in_target'] == True].copy()\n",
    "\n",
    "print('=== ターゲット範囲内の設定 (70%-85%) ===')\n",
    "if len(df_target) > 0:\n",
    "    print(df_target[['center_scale', 'noise_std', 'snr', 'train_acc', 'test_acc', 'test_std']].to_string(index=False))\n",
    "    \n",
    "    best_idx = df_target['test_std'].idxmin()\n",
    "    best = df_target.loc[best_idx]\n",
    "    print(f'\\n★ 推奨設定（最小分散）:')\n",
    "    print(f'   center_scale = {best[\"center_scale\"]}')\n",
    "    print(f'   noise_std = {best[\"noise_std\"]}')\n",
    "    print(f'   SNR = {best[\"snr\"]:.2f}')\n",
    "    print(f'   test_acc = {best[\"test_acc\"]:.3f} ± {best[\"test_std\"]:.3f}')\n",
    "else:\n",
    "    print('ターゲット範囲内の設定が見つかりませんでした。')\n",
    "    print('\\n全設定の結果:')\n",
    "    print(df[['center_scale', 'noise_std', 'snr', 'train_acc', 'test_acc']].to_string(index=False))\n",
    "    \n",
    "    # 最も近い設定\n",
    "    target_center = (TARGET_ACC_MIN + TARGET_ACC_MAX) / 2\n",
    "    df['distance'] = np.abs(df['test_acc'] - target_center)\n",
    "    closest = df.loc[df['distance'].idxmin()]\n",
    "    print(f'\\n最もターゲット({target_center:.0%})に近い設定:')\n",
    "    print(f'   center_scale = {closest[\"center_scale\"]}, noise_std = {closest[\"noise_std\"]}')\n",
    "    print(f'   SNR = {closest[\"snr\"]:.2f}')\n",
    "    print(f'   test_acc = {closest[\"test_acc\"]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ヒートマップ可視化\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "pivot_test = df.pivot(index='noise_std', columns='center_scale', values='test_acc')\n",
    "\n",
    "ax1 = axes[0]\n",
    "im1 = ax1.imshow(pivot_test.values, cmap='RdYlGn', aspect='auto', vmin=0.1, vmax=1.0)\n",
    "ax1.set_xticks(range(len(CENTER_SCALES)))\n",
    "ax1.set_xticklabels(CENTER_SCALES)\n",
    "ax1.set_yticks(range(len(NOISE_STDS)))\n",
    "ax1.set_yticklabels(NOISE_STDS)\n",
    "ax1.set_xlabel('center_scale', fontsize=12)\n",
    "ax1.set_ylabel('noise_std', fontsize=12)\n",
    "ax1.set_title('Test Accuracy (Clean Training)', fontsize=14, fontweight='bold')\n",
    "plt.colorbar(im1, ax=ax1, label='Accuracy')\n",
    "\n",
    "for i in range(len(NOISE_STDS)):\n",
    "    for j in range(len(CENTER_SCALES)):\n",
    "        val = pivot_test.values[i, j]\n",
    "        color = 'white' if val < 0.5 else 'black'\n",
    "        weight = 'bold' if TARGET_ACC_MIN <= val <= TARGET_ACC_MAX else 'normal'\n",
    "        ax1.text(j, i, f'{val:.2f}', ha='center', va='center', \n",
    "                fontsize=9, color=color, fontweight=weight)\n",
    "\n",
    "ax2 = axes[1]\n",
    "pivot_in_target = df.pivot(index='noise_std', columns='center_scale', values='in_target')\n",
    "im2 = ax2.imshow(pivot_in_target.values.astype(float), cmap='Blues', aspect='auto', vmin=0, vmax=1)\n",
    "ax2.set_xticks(range(len(CENTER_SCALES)))\n",
    "ax2.set_xticklabels(CENTER_SCALES)\n",
    "ax2.set_yticks(range(len(NOISE_STDS)))\n",
    "ax2.set_yticklabels(NOISE_STDS)\n",
    "ax2.set_xlabel('center_scale', fontsize=12)\n",
    "ax2.set_ylabel('noise_std', fontsize=12)\n",
    "ax2.set_title(f'In Target Range ({TARGET_ACC_MIN*100:.0f}%-{TARGET_ACC_MAX*100:.0f}%)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "\n",
    "for i in range(len(NOISE_STDS)):\n",
    "    for j in range(len(CENTER_SCALES)):\n",
    "        val = pivot_in_target.values[i, j]\n",
    "        ax2.text(j, i, '★' if val else '', ha='center', va='center', fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{SAVE_DIR}/calibration_heatmap_v4.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果の保存\n",
    "\n",
    "df.to_csv(f'{SAVE_DIR}/calibration_results_v4.csv', index=False)\n",
    "\n",
    "if len(df_target) > 0:\n",
    "    best_idx = df_target['test_std'].idxmin()\n",
    "    best = df_target.loc[best_idx]\n",
    "    \n",
    "    calibration_config = {\n",
    "        'calibration_rule': 'Clean training test accuracy in 70-85% range',\n",
    "        'version': 'v4 (adjusted SNR range)',\n",
    "        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'recommended_settings': {\n",
    "            'center_scale': float(best['center_scale']),\n",
    "            'noise_std': float(best['noise_std']),\n",
    "            'snr': float(best['snr']),\n",
    "            'expected_test_acc': float(best['test_acc']),\n",
    "            'test_acc_std': float(best['test_std'])\n",
    "        },\n",
    "        'data_settings': {\n",
    "            'n_train': N_TRAIN,\n",
    "            'n_test': N_TEST,\n",
    "            'n_classes': N_CLASSES,\n",
    "            'dim_per_view': DIM_PER_VIEW,\n",
    "            'center_seed': CENTER_SEED\n",
    "        },\n",
    "        'all_valid_settings': df_target[['center_scale', 'noise_std', 'snr', 'test_acc', 'test_std']].to_dict('records')\n",
    "    }\n",
    "else:\n",
    "    target_center = (TARGET_ACC_MIN + TARGET_ACC_MAX) / 2\n",
    "    df['distance'] = np.abs(df['test_acc'] - target_center)\n",
    "    closest = df.loc[df['distance'].idxmin()]\n",
    "    \n",
    "    calibration_config = {\n",
    "        'calibration_rule': 'Clean training test accuracy in 70-85% range',\n",
    "        'version': 'v4 (adjusted SNR range)',\n",
    "        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'warning': 'No settings found in target range',\n",
    "        'closest_settings': {\n",
    "            'center_scale': float(closest['center_scale']),\n",
    "            'noise_std': float(closest['noise_std']),\n",
    "            'snr': float(closest['snr']),\n",
    "            'expected_test_acc': float(closest['test_acc']),\n",
    "            'test_acc_std': float(closest['test_std'])\n",
    "        },\n",
    "        'data_settings': {\n",
    "            'n_train': N_TRAIN,\n",
    "            'n_test': N_TEST,\n",
    "            'n_classes': N_CLASSES,\n",
    "            'dim_per_view': DIM_PER_VIEW,\n",
    "            'center_seed': CENTER_SEED\n",
    "        }\n",
    "    }\n",
    "\n",
    "with open(f'{SAVE_DIR}/calibration_config_v4.json', 'w') as f:\n",
    "    json.dump(calibration_config, f, indent=2)\n",
    "\n",
    "print('\\n=== 保存完了 ===')\n",
    "print(f'  {SAVE_DIR}/calibration_results_v4.csv')\n",
    "print(f'  {SAVE_DIR}/calibration_config_v4.json')\n",
    "print(f'  {SAVE_DIR}/calibration_heatmap_v4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最終サマリー\n",
    "\n",
    "print('\\n' + '=' * 70)\n",
    "print('較正実験 v4 完了')\n",
    "print('=' * 70)\n",
    "\n",
    "print('\\n■ v4での修正:')\n",
    "print('  SNR範囲を下げて課題を難しくした')\n",
    "print(f'  center_scale: {CENTER_SCALES}')\n",
    "print(f'  noise_std: {NOISE_STDS}')\n",
    "\n",
    "if len(df_target) > 0:\n",
    "    best_idx = df_target['test_std'].idxmin()\n",
    "    best = df_target.loc[best_idx]\n",
    "    \n",
    "    print('\\n■ 推奨設定:')\n",
    "    print(f'  center_scale = {best[\"center_scale\"]}')\n",
    "    print(f'  noise_std = {best[\"noise_std\"]}')\n",
    "    print(f'  SNR = {best[\"snr\"]:.2f}')\n",
    "    print(f'  → test_acc = {best[\"test_acc\"]:.1%} ± {best[\"test_std\"]:.1%}')\n",
    "    \n",
    "    print('\\n■ 次のステップ:')\n",
    "    print('  1. この設定でE3縮小版（90 runs）を実行')\n",
    "    print('  2. 交絡の観察を確認')\n",
    "    print('  3. 本番E3を実行')\n",
    "else:\n",
    "    print('\\n⚠️ ターゲット範囲内の設定が見つかりませんでした。')\n",
    "    print('  結果を確認し、探索範囲の追加調整を検討してください。')\n",
    "\n",
    "print('\\n' + '=' * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
