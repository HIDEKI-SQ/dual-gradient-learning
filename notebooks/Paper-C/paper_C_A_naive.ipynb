{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper C - Fig C9: A_naive Confounding Demonstration\n",
    "\n",
    "## 目的\n",
    "交絡（confounding）の実証：\n",
    "- **A_naive = cos(g_mix, g_ref)** がλに依存することを示す\n",
    "- ρを固定しても、A_naiveはλで変動してしまう\n",
    "- これが「方向と使用量の交絡」の本質\n",
    "\n",
    "## 設計\n",
    "- 較正済み設定（center_scale=2.5, noise_std=1.0）\n",
    "- 軽量版：180 runs（約5分）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "SAVE_DIR = '/content/drive/MyDrive/paper-C-results/E3_A_naive'\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "print(f'Save directory: {SAVE_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 較正済み設定\n",
    "CENTER_SCALE = 2.5\n",
    "NOISE_STD_DATA = 1.0\n",
    "N_TRAIN = 20000\n",
    "N_TEST = 10000\n",
    "N_CLASSES = 10\n",
    "DIM_PER_VIEW = 8\n",
    "CENTER_SEED = 0\n",
    "\n",
    "# 軽量グリッド\n",
    "NOISE_RATES = [0.0, 0.3, 0.5]\n",
    "RHO_VALUES = [0.0, 0.4, 0.7, 1.0]  # 4点に絞る\n",
    "LAMBDA_VALUES = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "SEEDS = [0, 1, 2]  # 3 seeds\n",
    "\n",
    "EPOCHS = 100\n",
    "LR = 0.1\n",
    "\n",
    "TOTAL_RUNS = len(NOISE_RATES) * len(RHO_VALUES) * len(LAMBDA_VALUES) * len(SEEDS)\n",
    "print(f'Total runs: {TOTAL_RUNS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ生成関数（E3と同じ）\n",
    "\n",
    "def generate_orthogonal_centers(n_classes, dim_per_view, center_scale, seed=0):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    total_dim = dim_per_view * 2\n",
    "    random_matrix = rng.randn(total_dim, n_classes)\n",
    "    Q, _ = np.linalg.qr(random_matrix)\n",
    "    centers_joint = Q[:, :n_classes].T * center_scale\n",
    "    centers_A = centers_joint[:, :dim_per_view]\n",
    "    centers_B = centers_joint[:, dim_per_view:]\n",
    "    return centers_A.astype(np.float32), centers_B.astype(np.float32)\n",
    "\n",
    "def generate_two_view_data(n_samples, centers_A, centers_B, noise_std, sample_seed):\n",
    "    n_classes = centers_A.shape[0]\n",
    "    dim_per_view = centers_A.shape[1]\n",
    "    rng = np.random.RandomState(sample_seed)\n",
    "    labels = rng.randint(0, n_classes, n_samples)\n",
    "    view_A = np.array([centers_A[l] + rng.randn(dim_per_view) * noise_std for l in labels])\n",
    "    view_B = np.array([centers_B[l] + rng.randn(dim_per_view) * noise_std for l in labels])\n",
    "    X = np.concatenate([view_A, view_B], axis=1)\n",
    "    return X.astype(np.float32), labels.astype(np.int64)\n",
    "\n",
    "def inject_label_noise(labels, noise_rate, n_classes=10, seed=42):\n",
    "    if noise_rate == 0:\n",
    "        return labels.copy()\n",
    "    rng = np.random.RandomState(seed + 1000)\n",
    "    noisy = labels.copy()\n",
    "    n_noisy = int(noise_rate * len(labels))\n",
    "    indices = rng.choice(len(labels), n_noisy, replace=False)\n",
    "    for idx in indices:\n",
    "        noisy[idx] = rng.choice([i for i in range(n_classes) if i != labels[idx]])\n",
    "    return noisy\n",
    "\n",
    "print('データ生成関数定義完了')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル定義\n",
    "\n",
    "class TwoViewMLP(nn.Module):\n",
    "    def __init__(self, input_dim=16, hidden_dim=64, n_classes=10):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, n_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "print('モデル定義完了')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 勾配操作関数\n",
    "\n",
    "def get_gradient_vector(model):\n",
    "    grads = []\n",
    "    for p in model.parameters():\n",
    "        if p.grad is not None:\n",
    "            grads.append(p.grad.view(-1))\n",
    "    return torch.cat(grads)\n",
    "\n",
    "def set_gradient_vector(model, grad_vec):\n",
    "    idx = 0\n",
    "    for p in model.parameters():\n",
    "        numel = p.numel()\n",
    "        p.grad = grad_vec[idx:idx+numel].view(p.shape).clone()\n",
    "        idx += numel\n",
    "\n",
    "def orthogonalize(g_ref_norm, v):\n",
    "    v_perp = v - torch.dot(v, g_ref_norm) * g_ref_norm\n",
    "    norm = torch.norm(v_perp)\n",
    "    if norm < 1e-10:\n",
    "        v = torch.randn_like(v)\n",
    "        v_perp = v - torch.dot(v, g_ref_norm) * g_ref_norm\n",
    "        norm = torch.norm(v_perp)\n",
    "    return v_perp / norm\n",
    "\n",
    "def construct_g_value(g_ref_norm, rho, device):\n",
    "    random_vec = torch.randn_like(g_ref_norm)\n",
    "    g_perp = orthogonalize(g_ref_norm, random_vec)\n",
    "    \n",
    "    if abs(rho) >= 1.0:\n",
    "        g_value = rho * g_ref_norm\n",
    "    else:\n",
    "        sqrt_term = np.sqrt(1 - rho**2)\n",
    "        g_value = rho * g_ref_norm + sqrt_term * g_perp\n",
    "    \n",
    "    g_value = g_value / torch.norm(g_value)\n",
    "    return g_value, g_perp\n",
    "\n",
    "print('勾配操作関数定義完了')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ★ A_naive計測を追加した実験関数\n",
    "\n",
    "def run_experiment_with_A_naive(noise_rate, rho, lam, model_seed):\n",
    "    \"\"\"\n",
    "    A_naive = cos(g_mix, g_ref) を記録する実験\n",
    "    \"\"\"\n",
    "    centers_A, centers_B = generate_orthogonal_centers(\n",
    "        N_CLASSES, DIM_PER_VIEW, CENTER_SCALE, seed=CENTER_SEED\n",
    "    )\n",
    "    \n",
    "    X_train, y_train_clean = generate_two_view_data(\n",
    "        N_TRAIN, centers_A, centers_B, NOISE_STD_DATA, sample_seed=42\n",
    "    )\n",
    "    X_test, y_test = generate_two_view_data(\n",
    "        N_TEST, centers_A, centers_B, NOISE_STD_DATA, sample_seed=43\n",
    "    )\n",
    "    \n",
    "    y_train_noisy = inject_label_noise(y_train_clean, noise_rate, N_CLASSES, seed=model_seed)\n",
    "    \n",
    "    X_train_t = torch.tensor(X_train, device=device)\n",
    "    y_clean_t = torch.tensor(y_train_clean, device=device)\n",
    "    y_noisy_t = torch.tensor(y_train_noisy, device=device)\n",
    "    X_test_t = torch.tensor(X_test, device=device)\n",
    "    y_test_t = torch.tensor(y_test, device=device)\n",
    "    \n",
    "    set_seed(model_seed)\n",
    "    model = TwoViewMLP().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # ★ A_naive記録用\n",
    "    A_naive_values = []\n",
    "    cos_gval_gref_values = []  # cos(g_value, g_ref) も記録\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        \n",
    "        # g_ref（clean labels）\n",
    "        optimizer.zero_grad()\n",
    "        loss_ref = criterion(model(X_train_t), y_clean_t)\n",
    "        loss_ref.backward()\n",
    "        g_ref = get_gradient_vector(model).clone()\n",
    "        g_ref_norm = g_ref / torch.norm(g_ref)\n",
    "        g_ref_scale = torch.norm(g_ref)\n",
    "        \n",
    "        # g_struct（noisy labels）\n",
    "        optimizer.zero_grad()\n",
    "        loss_struct = criterion(model(X_train_t), y_noisy_t)\n",
    "        loss_struct.backward()\n",
    "        g_struct = get_gradient_vector(model).clone()\n",
    "        g_struct_norm = g_struct / torch.norm(g_struct)\n",
    "        g_struct_scale = torch.norm(g_struct)\n",
    "        \n",
    "        # g_value（ρ-design）\n",
    "        g_value, _ = construct_g_value(g_ref_norm, rho, device)\n",
    "        \n",
    "        # cos(g_value, g_ref) の検証\n",
    "        cos_gval_gref = torch.dot(g_value, g_ref_norm).item()\n",
    "        cos_gval_gref_values.append(cos_gval_gref)\n",
    "        \n",
    "        # g_mix = λ * g_struct + (1-λ) * g_value\n",
    "        g_mix = lam * g_struct_norm + (1 - lam) * g_value\n",
    "        g_mix_norm = g_mix / torch.norm(g_mix)\n",
    "        \n",
    "        # ★ A_naive = cos(g_mix, g_ref)\n",
    "        A_naive = torch.dot(g_mix_norm, g_ref_norm).item()\n",
    "        A_naive_values.append(A_naive)\n",
    "        \n",
    "        # スケール復元して更新\n",
    "        g_mix_scaled = g_mix_norm * g_struct_scale\n",
    "        optimizer.zero_grad()\n",
    "        set_gradient_vector(model, g_mix_scaled)\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 評価\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_acc = (model(X_test_t).argmax(1) == y_test_t).float().mean().item()\n",
    "    \n",
    "    return {\n",
    "        'noise_rate': noise_rate,\n",
    "        'rho': rho,\n",
    "        'lambda': lam,\n",
    "        'seed': model_seed,\n",
    "        'test_acc': test_acc,\n",
    "        'A_naive_mean': np.mean(A_naive_values),\n",
    "        'A_naive_std': np.std(A_naive_values),\n",
    "        'A_naive_final': A_naive_values[-1],\n",
    "        'cos_gval_gref_mean': np.mean(cos_gval_gref_values)\n",
    "    }\n",
    "\n",
    "print('実験関数定義完了（A_naive計測付き）')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 動作確認\n",
    "\n",
    "print('=== 動作確認 ===')\n",
    "result = run_experiment_with_A_naive(noise_rate=0.3, rho=0.7, lam=0.5, model_seed=0)\n",
    "print(f'noise=30%, ρ=0.7, λ=0.5')\n",
    "print(f'  test_acc = {result[\"test_acc\"]:.3f}')\n",
    "print(f'  cos(g_val, g_ref) = {result[\"cos_gval_gref_mean\"]:.4f} (target: 0.7)')\n",
    "print(f'  A_naive = cos(g_mix, g_ref) = {result[\"A_naive_mean\"]:.4f}')\n",
    "print('\\n✓ 動作確認OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本番実験\n",
    "\n",
    "print('\\n' + '=' * 60)\n",
    "print('A_naive Confounding Experiment')\n",
    "print(f'Total: {TOTAL_RUNS} runs')\n",
    "print('=' * 60 + '\\n')\n",
    "\n",
    "results = []\n",
    "start_time = time.time()\n",
    "run_count = 0\n",
    "\n",
    "for noise_rate in NOISE_RATES:\n",
    "    noise_pct = int(noise_rate * 100)\n",
    "    print(f'\\n=== NOISE {noise_pct}% ===')\n",
    "    \n",
    "    for rho in RHO_VALUES:\n",
    "        for lam in LAMBDA_VALUES:\n",
    "            for seed in SEEDS:\n",
    "                run_count += 1\n",
    "                result = run_experiment_with_A_naive(noise_rate, rho, lam, seed)\n",
    "                results.append(result)\n",
    "                \n",
    "                if run_count % 30 == 0:\n",
    "                    elapsed = time.time() - start_time\n",
    "                    eta = elapsed / run_count * (TOTAL_RUNS - run_count)\n",
    "                    print(f'  [{run_count:3d}/{TOTAL_RUNS}] ρ={rho:+.1f} λ={lam:.2f} | '\n",
    "                          f'A_naive={result[\"A_naive_mean\"]:.3f} | ETA: {eta/60:.1f}min')\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f'\\n完了！ Total time: {total_time/60:.1f} min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果集計\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "df_agg = df.groupby(['noise_rate', 'rho', 'lambda']).agg({\n",
    "    'test_acc': ['mean', 'std'],\n",
    "    'A_naive_mean': ['mean', 'std'],\n",
    "    'cos_gval_gref_mean': ['mean']\n",
    "}).reset_index()\n",
    "df_agg.columns = ['noise_rate', 'rho', 'lambda', \n",
    "                  'test_acc_mean', 'test_acc_std',\n",
    "                  'A_naive_mean', 'A_naive_std',\n",
    "                  'cos_gval_gref']\n",
    "\n",
    "print('集計完了')\n",
    "print(df_agg.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ★ Fig C9: A_naive のλ依存（交絡の実証）\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(RHO_VALUES)))\n",
    "\n",
    "for idx, noise_rate in enumerate(NOISE_RATES):\n",
    "    ax = axes[idx]\n",
    "    noise_pct = int(noise_rate * 100)\n",
    "    \n",
    "    df_noise = df_agg[df_agg['noise_rate'] == noise_rate]\n",
    "    \n",
    "    for rho_idx, rho in enumerate(RHO_VALUES):\n",
    "        df_rho = df_noise[df_noise['rho'] == rho]\n",
    "        ax.errorbar(df_rho['lambda'], df_rho['A_naive_mean'], \n",
    "                   yerr=df_rho['A_naive_std'],\n",
    "                   marker='o', label=f'ρ={rho:+.1f}', \n",
    "                   color=colors[rho_idx], capsize=3, linewidth=2)\n",
    "        \n",
    "        # ρの理想値を破線で表示\n",
    "        ax.axhline(y=rho, color=colors[rho_idx], linestyle='--', alpha=0.3)\n",
    "    \n",
    "    ax.set_xlabel('λ (structure weight)', fontsize=12)\n",
    "    ax.set_ylabel('A_naive = cos(g_mix, g_ref)', fontsize=12)\n",
    "    ax.set_title(f'Noise = {noise_pct}%', fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='best', fontsize=10)\n",
    "    ax.set_ylim(-0.2, 1.1)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 交絡の説明を追加\n",
    "    ax.text(0.5, -0.1, 'A_naive varies with λ\\n(confounding)', \n",
    "           ha='center', fontsize=9, style='italic', color='red')\n",
    "\n",
    "fig.suptitle('Fig C9: Confounding Demonstration\\nA_naive depends on λ even when ρ is fixed', \n",
    "            fontsize=16, fontweight='bold', y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{SAVE_DIR}/fig_C9_A_naive_confounding.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('✓ Fig C9 保存完了')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交絡の定量的評価\n",
    "\n",
    "print('\\n=== 交絡の定量的評価 ===')\n",
    "print('\\nρ固定時のA_naiveのλによる変動幅：')\n",
    "\n",
    "for noise_rate in NOISE_RATES:\n",
    "    noise_pct = int(noise_rate * 100)\n",
    "    print(f'\\nNoise = {noise_pct}%:')\n",
    "    \n",
    "    df_noise = df_agg[df_agg['noise_rate'] == noise_rate]\n",
    "    \n",
    "    for rho in RHO_VALUES:\n",
    "        df_rho = df_noise[df_noise['rho'] == rho]\n",
    "        A_naive_range = df_rho['A_naive_mean'].max() - df_rho['A_naive_mean'].min()\n",
    "        print(f'  ρ={rho:+.1f}: A_naive range = {A_naive_range:.3f} '\n",
    "              f'(min={df_rho[\"A_naive_mean\"].min():.3f}, max={df_rho[\"A_naive_mean\"].max():.3f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果保存\n",
    "\n",
    "df.to_csv(f'{SAVE_DIR}/A_naive_results_raw.csv', index=False)\n",
    "df_agg.to_csv(f'{SAVE_DIR}/A_naive_results_aggregated.csv', index=False)\n",
    "\n",
    "# サマリーJSON\n",
    "summary = {\n",
    "    'experiment': 'A_naive_confounding',\n",
    "    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'purpose': 'Demonstrate that A_naive = cos(g_mix, g_ref) depends on lambda (confounding)',\n",
    "    'grid': {\n",
    "        'noise_rates': NOISE_RATES,\n",
    "        'rho_values': RHO_VALUES,\n",
    "        'lambda_values': LAMBDA_VALUES,\n",
    "        'n_seeds': len(SEEDS)\n",
    "    },\n",
    "    'total_runs': TOTAL_RUNS,\n",
    "    'key_finding': 'A_naive varies with lambda even when rho is fixed, demonstrating confounding'\n",
    "}\n",
    "\n",
    "with open(f'{SAVE_DIR}/A_naive_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print('\\n=== 保存完了 ===')\n",
    "print(f'  {SAVE_DIR}/A_naive_results_raw.csv')\n",
    "print(f'  {SAVE_DIR}/A_naive_results_aggregated.csv')\n",
    "print(f'  {SAVE_DIR}/A_naive_summary.json')\n",
    "print(f'  {SAVE_DIR}/fig_C9_A_naive_confounding.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最終サマリー\n",
    "\n",
    "print('\\n' + '=' * 70)\n",
    "print('A_naive Confounding Experiment 完了')\n",
    "print('=' * 70)\n",
    "\n",
    "print('\\n■ 交絡の実証:')\n",
    "print('  A_naive = cos(g_mix, g_ref) は λ に依存する')\n",
    "print('  → ρ（方向）を測りたいのに、λ（使用量）の影響を受ける')\n",
    "print('  → これが「交絡」の本質')\n",
    "\n",
    "print('\\n■ Fig C9 の読み方:')\n",
    "print('  - 各線はρを固定')\n",
    "print('  - λを動かすとA_naiveが変動 → 交絡あり')\n",
    "print('  - 破線は「理想的なρ値」')\n",
    "\n",
    "print('\\n' + '=' * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
