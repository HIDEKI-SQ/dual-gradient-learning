{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V3: Architecture Universality (VGG11)\n",
    "\n",
    "**Purpose**: Confirm hysteresis is not ResNet-specific\n",
    "\n",
    "**Key Question**: Is the phenomenon architecture-universal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os, glob, json, time\n",
    "from datetime import datetime\n",
    "\n",
    "EXP_NAME = 'exp_V3_vgg11'\n",
    "NOTEBOOK_ID = 'V3'\n",
    "BASE_DIR = '/content/drive/MyDrive/dual-gradient-learning/Paper-A'\n",
    "\n",
    "existing = glob.glob(f'{BASE_DIR}/{EXP_NAME}_*')\n",
    "if existing:\n",
    "    SAVE_DIR = sorted(existing)[-1]\n",
    "    print(f'Resuming: {SAVE_DIR}')\n",
    "else:\n",
    "    TIMESTAMP = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    SAVE_DIR = f'{BASE_DIR}/{EXP_NAME}_{TIMESTAMP}'\n",
    "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "    print(f'New: {SAVE_DIR}')\n",
    "\n",
    "os.makedirs(f'{SAVE_DIR}/checkpoints', exist_ok=True)\n",
    "os.makedirs(f'{SAVE_DIR}/figures', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils import parameters_to_vector\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE, NUM_WORKERS, LR, K, NOISE_RATE = 128, 4, 0.05, 16, 0.4\n",
    "ORDERED_LAMBDA, ORDERED_EPOCHS, ORDERED_THRESHOLD = 0.35, 50, 0.25\n",
    "COLLAPSE_LAMBDA, COLLAPSE_EPOCHS, COLLAPSE_THRESHOLD = 0.60, 80, 0.45\n",
    "LAMBDA_START, LAMBDA_END, LAMBDA_STEP, EPOCHS_PER_LAMBDA = 0.30, 0.70, 0.05, 3\n",
    "LAMBDA_GRID_UP = np.round(np.arange(LAMBDA_START, LAMBDA_END + LAMBDA_STEP/2, LAMBDA_STEP), 2)\n",
    "LAMBDA_GRID_DOWN = np.round(np.arange(LAMBDA_END, LAMBDA_START - LAMBDA_STEP/2, -LAMBDA_STEP), 2)\n",
    "N_SEEDS = 3\n",
    "print(f'VGG11-BN, λ points: {len(LAMBDA_GRID_UP)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n",
    "\n",
    "class VGG11BN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_ch = 3\n",
    "        for v in cfg:\n",
    "            if v == 'M': layers += [nn.MaxPool2d(2, 2)]\n",
    "            else: layers += [nn.Conv2d(in_ch, v, 3, padding=1), nn.BatchNorm2d(v), nn.ReLU(True)]; in_ch = v\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        self.classifier = nn.Sequential(nn.Linear(512, 512), nn.ReLU(True), nn.Dropout(0.5), nn.Linear(512, num_classes))\n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.features(x).view(x.size(0), -1))\n",
    "\n",
    "def get_vgg11(): return VGG11BN()\n",
    "\n",
    "class IndexedDataset(Dataset):\n",
    "    def __init__(self, ds): self.ds = ds\n",
    "    def __getitem__(self, i): img, lbl = self.ds[i]; return img, lbl, i\n",
    "    def __len__(self): return len(self.ds)\n",
    "\n",
    "def set_seed(s): torch.manual_seed(s); torch.cuda.manual_seed_all(s); np.random.seed(s); torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def inject_noise(labels, rate, seed):\n",
    "    np.random.seed(seed); noisy = labels.copy(); idx = np.random.choice(len(labels), int(rate * len(labels)), False)\n",
    "    for i in idx: noisy[i] = np.random.choice([l for l in range(10) if l != labels[i]])\n",
    "    return noisy\n",
    "\n",
    "def load_cifar10():\n",
    "    tr = transforms.Compose([transforms.RandomCrop(32, 4), transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize((0.4914,0.4822,0.4465),(0.2023,0.1994,0.2010))])\n",
    "    te = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914,0.4822,0.4465),(0.2023,0.1994,0.2010))])\n",
    "    return torchvision.datasets.CIFAR10('./data', True, tr, download=True), torchvision.datasets.CIFAR10('./data', False, te, download=True)\n",
    "\n",
    "def evaluate(m, loader):\n",
    "    m.eval(); c = t = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader: x, y = x.to(device), y.to(device); c += (m(x).argmax(1) == y).sum().item(); t += y.size(0)\n",
    "    return c / t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, opt, clean_t, noisy_t, lam, state):\n",
    "    crit = nn.CrossEntropyLoss(); model.train(); step, cached_gv = state['step'], state['gv']\n",
    "    for x, _, idx in loader:\n",
    "        x, idx = x.to(device), idx.to(device); bn, bc = noisy_t[idx], clean_t[idx]\n",
    "        opt.zero_grad(); crit(model(x), bn).backward(retain_graph=True)\n",
    "        gs = parameters_to_vector([p.grad for p in model.parameters()]).clone()\n",
    "        if step % K == 0 or cached_gv is None:\n",
    "            opt.zero_grad(); crit(model(x), bc).backward()\n",
    "            cached_gv = parameters_to_vector([p.grad for p in model.parameters()]).clone()\n",
    "        gs_n, gv_n = gs / (gs.norm() + 1e-12), cached_gv / (cached_gv.norm() + 1e-12)\n",
    "        g_mix = (1 - lam) * gs_n + lam * gv_n\n",
    "        opt.zero_grad(); i = 0\n",
    "        for p in model.parameters(): n = p.numel(); p.grad = g_mix[i:i+n].view(p.shape).clone(); i += n\n",
    "        opt.step(); step += 1\n",
    "    state['step'], state['gv'] = step, cached_gv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = load_cifar10()\n",
    "clean_labels = np.array(trainset.targets)\n",
    "train_loader = DataLoader(IndexedDataset(trainset), BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_loader = DataLoader(testset, BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "m = get_vgg11().to(device); print(f'Params: {sum(p.numel() for p in m.parameters()):,}')\n",
    "for _ in range(3): _ = m(torch.randn(BATCH_SIZE,3,32,32,device=device))\n",
    "del m; torch.cuda.empty_cache(); print('Ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "ckpt_file = f'{SAVE_DIR}/{NOTEBOOK_ID}_checkpoint.json'\n",
    "done_seeds = set(json.load(open(ckpt_file))['seed'] for r in json.load(open(ckpt_file))) if os.path.exists(ckpt_file) else set()\n",
    "if os.path.exists(ckpt_file): results = json.load(open(ckpt_file)); done_seeds = {r['seed'] for r in results}\n",
    "\n",
    "for seed in range(N_SEEDS):\n",
    "    if seed in done_seeds: continue\n",
    "    print(f'\\n{\"=\"*50}\\nSEED {seed}\\n{\"=\"*50}')\n",
    "    noisy_labels = inject_noise(clean_labels, NOISE_RATE, seed)\n",
    "    clean_t, noisy_t = torch.tensor(clean_labels, device=device), torch.tensor(noisy_labels, device=device)\n",
    "    \n",
    "    # Ordered\n",
    "    print(f'Ordered...')\n",
    "    set_seed(seed); model = get_vgg11().to(device)\n",
    "    opt = optim.SGD(model.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4)\n",
    "    sched = optim.lr_scheduler.MultiStepLR(opt, [25, 40], 0.1); state = {'step': 0, 'gv': None}\n",
    "    for ep in range(ORDERED_EPOCHS): train_epoch(model, train_loader, opt, clean_t, noisy_t, ORDERED_LAMBDA, state); sched.step()\n",
    "    ordered_error = 1 - evaluate(model, test_loader); print(f'  {ordered_error:.4f}')\n",
    "    if ordered_error >= ORDERED_THRESHOLD: print('  Failed'); continue\n",
    "    ordered_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}; del model; torch.cuda.empty_cache()\n",
    "    \n",
    "    # Collapse\n",
    "    print(f'Collapse...')\n",
    "    set_seed(seed + 100); model = get_vgg11().to(device)\n",
    "    opt = optim.SGD(model.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4)\n",
    "    sched = optim.lr_scheduler.MultiStepLR(opt, [40, 60], 0.1); state = {'step': 0, 'gv': None}\n",
    "    for ep in range(COLLAPSE_EPOCHS): train_epoch(model, train_loader, opt, clean_t, noisy_t, COLLAPSE_LAMBDA, state); sched.step()\n",
    "    collapse_error = 1 - evaluate(model, test_loader); print(f'  {collapse_error:.4f}')\n",
    "    if collapse_error < COLLAPSE_THRESHOLD: print('  Failed'); continue\n",
    "    collapse_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}; del model; torch.cuda.empty_cache()\n",
    "    \n",
    "    # Sweep ordered\n",
    "    print(f'Sweep ordered...')\n",
    "    set_seed(seed + 200); model = get_vgg11().to(device)\n",
    "    model.load_state_dict({k: v.to(device) for k, v in ordered_state.items()})\n",
    "    opt = optim.SGD(model.parameters(), lr=LR * 0.01, momentum=0.9, weight_decay=5e-4); state = {'step': 0, 'gv': None}\n",
    "    ordered_traj = []\n",
    "    for lam in LAMBDA_GRID_UP:\n",
    "        for _ in range(EPOCHS_PER_LAMBDA): train_epoch(model, train_loader, opt, clean_t, noisy_t, lam, state)\n",
    "        err = 1 - evaluate(model, test_loader); ordered_traj.append({'lambda': float(lam), 'error': err}); print(f'  {lam:.2f}: {err:.4f}')\n",
    "    del model; torch.cuda.empty_cache()\n",
    "    \n",
    "    # Sweep collapse\n",
    "    print(f'Sweep collapse...')\n",
    "    set_seed(seed + 300); model = get_vgg11().to(device)\n",
    "    model.load_state_dict({k: v.to(device) for k, v in collapse_state.items()})\n",
    "    opt = optim.SGD(model.parameters(), lr=LR * 0.01, momentum=0.9, weight_decay=5e-4); state = {'step': 0, 'gv': None}\n",
    "    collapse_traj = []\n",
    "    for lam in LAMBDA_GRID_DOWN:\n",
    "        for _ in range(EPOCHS_PER_LAMBDA): train_epoch(model, train_loader, opt, clean_t, noisy_t, lam, state)\n",
    "        err = 1 - evaluate(model, test_loader); collapse_traj.append({'lambda': float(lam), 'error': err}); print(f'  {lam:.2f}: {err:.4f}')\n",
    "    \n",
    "    results.append({'seed': seed, 'arch': 'VGG11-BN', 'ordered_init': ordered_error, 'collapse_init': collapse_error,\n",
    "                    'ordered_trajectory': ordered_traj, 'collapse_trajectory': collapse_traj, 'experiment_id': f'{NOTEBOOK_ID}-s{seed}'})\n",
    "    json.dump(results, open(ckpt_file, 'w'), indent=2); del model; torch.cuda.empty_cache()\n",
    "\n",
    "print(f'\\n{NOTEBOOK_ID} COMPLETE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "json.dump(results, open(f'{SAVE_DIR}/{NOTEBOOK_ID}_results.json', 'w'), indent=2)\n",
    "all_data = []\n",
    "for r in results:\n",
    "    for t in r['ordered_trajectory']: all_data.append({'seed': r['seed'], 'branch': 'ordered', 'lambda': t['lambda'], 'error': t['error']})\n",
    "    for t in r['collapse_trajectory']: all_data.append({'seed': r['seed'], 'branch': 'collapse', 'lambda': t['lambda'], 'error': t['error']})\n",
    "df = pd.DataFrame(all_data); df.to_csv(f'{SAVE_DIR}/{NOTEBOOK_ID}_results.csv', index=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for branch, color, marker in [('ordered', 'blue', 'o'), ('collapse', 'red', 's')]:\n",
    "    dfb = df[df['branch'] == branch]\n",
    "    if len(dfb) > 0:\n",
    "        m = dfb.groupby('lambda')['error'].agg(['mean', 'std']).reset_index()\n",
    "        ax.fill_between(m['lambda'], m['mean']-m['std'], m['mean']+m['std'], alpha=0.3, color=color)\n",
    "        ax.plot(m['lambda'], m['mean'], f'{color[0]}-{marker}', linewidth=2, label=branch.capitalize())\n",
    "\n",
    "ax.axhline(0.40, color='orange', linestyle='--', alpha=0.5)\n",
    "ax.set_xlabel('λ'); ax.set_ylabel('Test Error'); ax.set_title('VGG11: Hysteresis', fontweight='bold')\n",
    "ax.legend(); ax.grid(True, alpha=0.3); ax.set_xlim(0.28, 0.72)\n",
    "plt.tight_layout(); plt.savefig(f'{SAVE_DIR}/figures/{NOTEBOOK_ID}_hysteresis.png', dpi=150); plt.show()\n",
    "\n",
    "print('\\nSUMMARY')\n",
    "if len(df[df['branch']=='ordered']) > 0 and len(df[df['branch']=='collapse']) > 0:\n",
    "    ord_err = df[(df['branch']=='ordered') & (df['lambda']==0.50)]['error'].mean()\n",
    "    col_err = df[(df['branch']=='collapse') & (df['lambda']==0.50)]['error'].mean()\n",
    "    gap = col_err - ord_err\n",
    "    print(f'Gap at λ=0.50: {gap*100:.1f}%\\nTwo-branch: {\"YES\" if gap > 0.10 else \"NO\"}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
