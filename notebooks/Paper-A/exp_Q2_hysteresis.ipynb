{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp Q2: Hysteresis / Path Dependence\n",
    "\n",
    "## ç›®çš„\n",
    "ç›¸ãŒã€ŒçŠ¶æ…‹ã€ãªã‚‰ã€Î»ã‚’é€”ä¸­ã§å¤‰ãˆãŸæ™‚ã«ã€Œæˆ»ã‚‰ãªã•ã€ï¼ˆå±¥æ­´ä¾å­˜ï¼‰ãŒå‡ºã‚‹å¯èƒ½æ€§ã‚’æ¤œè¨¼ã€‚\n",
    "å‡ºã‚Œã°ä¸€æ¬¡è»¢ç§»æ§˜ã®è¨¼æ‹ ã«ãªã‚Šã€PREçš„ã«å¼·ã„ã€‚\n",
    "\n",
    "## å®Ÿé¨“è¨­è¨ˆ\n",
    "- **Schedules**:\n",
    "  1. Fixedï¼ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼‰\n",
    "  2. Quench: orderedâ†’collapseï¼ˆepoch 30ã§ Î»: 0.35â†’0.60ï¼‰\n",
    "  3. Reverse quench: collapseâ†’orderedï¼ˆepoch 30ã§ Î»: 0.60â†’0.35ï¼‰\n",
    "  4. Ramp upï¼ˆç·šå½¢ã§ä¸Šæ˜‡ï¼‰\n",
    "  5. Ramp downï¼ˆç·šå½¢ã§ä¸‹é™ï¼‰\n",
    "- **Î·**: 0.4, 0.8\n",
    "- **Seeds**: 5\n",
    "- **Total**: 5 schedules Ã— 2 Î· Ã— 5 seeds = **50 runs**\n",
    "\n",
    "## æ¨å®šæ™‚é–“\n",
    "~50 runs Ã— 9 min â‰ˆ **7.5 æ™‚é–“**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— =====\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "EXP_NAME = 'exp_Q2_hysteresis'\n",
    "BASE_DIR = '/content/drive/MyDrive/dual-gradient-learning/Paper-A'\n",
    "\n",
    "existing = glob.glob(f'{BASE_DIR}/{EXP_NAME}_*')\n",
    "if existing:\n",
    "    SAVE_DIR = sorted(existing)[-1]\n",
    "    print(f'ğŸ”„ Resuming from: {SAVE_DIR}')\n",
    "else:\n",
    "    TIMESTAMP = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    SAVE_DIR = f'{BASE_DIR}/{EXP_NAME}_{TIMESTAMP}'\n",
    "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "    print(f'ğŸ†• New experiment: {SAVE_DIR}')\n",
    "\n",
    "os.makedirs(f'{SAVE_DIR}/figures', exist_ok=True)\n",
    "print(f'Save directory: {SAVE_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils import parameters_to_vector\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ResNet18 for CIFAR-10 =====\n",
    "def get_resnet18():\n",
    "    model = resnet18(weights=None, num_classes=10)\n",
    "    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    model.maxpool = nn.Identity()\n",
    "    return model\n",
    "\n",
    "# ===== IndexedDataset =====\n",
    "class IndexedDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.dataset[idx]\n",
    "        return img, label, idx\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Î»ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å®šç¾© =====\n",
    "\n",
    "class LambdaSchedule:\n",
    "    \"\"\"Î»ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ç®¡ç†\"\"\"\n",
    "    def __init__(self, schedule_type, eta, total_epochs=100):\n",
    "        self.schedule_type = schedule_type\n",
    "        self.eta = eta\n",
    "        self.total_epochs = total_epochs\n",
    "        \n",
    "        # Î·ä¾å­˜ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š\n",
    "        if eta == 0.4:\n",
    "            self.lam_ordered = 0.35\n",
    "            self.lam_collapse = 0.60\n",
    "            self.lam_critical = 0.48\n",
    "        else:  # eta == 0.8\n",
    "            self.lam_ordered = 0.35\n",
    "            self.lam_collapse = 0.55\n",
    "            self.lam_critical = 0.44\n",
    "        \n",
    "        self.quench_epoch = 30  # ã‚¯ã‚¨ãƒ³ãƒã‚’è¡Œã†ã‚¨ãƒãƒƒã‚¯\n",
    "    \n",
    "    def get_lambda(self, epoch):\n",
    "        if self.schedule_type == 'fixed_ordered':\n",
    "            return self.lam_ordered\n",
    "        \n",
    "        elif self.schedule_type == 'fixed_collapse':\n",
    "            return self.lam_collapse\n",
    "        \n",
    "        elif self.schedule_type == 'quench_to_collapse':\n",
    "            # ordered â†’ collapse at epoch 30\n",
    "            if epoch < self.quench_epoch:\n",
    "                return self.lam_ordered\n",
    "            else:\n",
    "                return self.lam_collapse\n",
    "        \n",
    "        elif self.schedule_type == 'quench_to_ordered':\n",
    "            # collapse â†’ ordered at epoch 30\n",
    "            if epoch < self.quench_epoch:\n",
    "                return self.lam_collapse\n",
    "            else:\n",
    "                return self.lam_ordered\n",
    "        \n",
    "        elif self.schedule_type == 'ramp_up':\n",
    "            # ç·šå½¢ã«ä¸Šæ˜‡: ordered â†’ collapse\n",
    "            progress = epoch / self.total_epochs\n",
    "            return self.lam_ordered + progress * (self.lam_collapse - self.lam_ordered)\n",
    "        \n",
    "        elif self.schedule_type == 'ramp_down':\n",
    "            # ç·šå½¢ã«ä¸‹é™: collapse â†’ ordered\n",
    "            progress = epoch / self.total_epochs\n",
    "            return self.lam_collapse - progress * (self.lam_collapse - self.lam_ordered)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f'Unknown schedule: {self.schedule_type}')\n",
    "    \n",
    "    def describe(self):\n",
    "        return f'{self.schedule_type} (Î·={self.eta})'\n",
    "\n",
    "# ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ãƒ†ã‚¹ãƒˆè¡¨ç¤º\n",
    "print('Lambda schedules (Î·=0.4):')\n",
    "for stype in ['fixed_ordered', 'fixed_collapse', 'quench_to_collapse', 'quench_to_ordered', 'ramp_up', 'ramp_down']:\n",
    "    sched = LambdaSchedule(stype, 0.4)\n",
    "    lambdas = [sched.get_lambda(e) for e in [0, 29, 30, 50, 99]]\n",
    "    print(f'  {stype}: {lambdas}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== å®Ÿé¨“ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ =====\n",
    "BATCH_SIZE = 256\n",
    "NUM_WORKERS = 4\n",
    "EPOCHS = 100\n",
    "LR = 0.1\n",
    "K = 16\n",
    "\n",
    "SCHEDULE_TYPES = [\n",
    "    'fixed_ordered',      # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆorderedï¼‰\n",
    "    'fixed_collapse',     # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆcollapseï¼‰\n",
    "    'quench_to_collapse', # ordered â†’ collapse\n",
    "    'quench_to_ordered',  # collapse â†’ ordered\n",
    "    'ramp_up',            # ç·šå½¢ä¸Šæ˜‡\n",
    "    'ramp_down'           # ç·šå½¢ä¸‹é™\n",
    "]\n",
    "\n",
    "NOISE_RATES = [0.4, 0.8]\n",
    "SEEDS = list(range(5))\n",
    "\n",
    "experiments = []\n",
    "for stype in SCHEDULE_TYPES:\n",
    "    for eta in NOISE_RATES:\n",
    "        for seed in SEEDS:\n",
    "            experiments.append({\n",
    "                'schedule_type': stype,\n",
    "                'noise_rate': eta,\n",
    "                'seed': seed\n",
    "            })\n",
    "\n",
    "print(f'Schedule types: {SCHEDULE_TYPES}')\n",
    "print(f'Noise rates: {NOISE_RATES}')\n",
    "print(f'Total experiments: {len(experiments)}')\n",
    "print(f'Estimated time: {len(experiments) * 9 / 60:.1f} hours')\n",
    "\n",
    "# Save config\n",
    "config = {\n",
    "    'experiment': EXP_NAME,\n",
    "    'description': 'Hysteresis/path dependence: Î» schedule effects',\n",
    "    'parameters': {\n",
    "        'schedule_types': SCHEDULE_TYPES,\n",
    "        'noise_rates': NOISE_RATES,\n",
    "        'seeds': SEEDS,\n",
    "        'epochs': EPOCHS,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'lr': LR,\n",
    "        'K': K,\n",
    "        'quench_epoch': 30\n",
    "    },\n",
    "    'total_runs': len(experiments)\n",
    "}\n",
    "with open(f'{SAVE_DIR}/{EXP_NAME}_config.json', 'w') as f:\n",
    "    json.dump(config, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° =====\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "def load_cifar10():\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "    ])\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "    ])\n",
    "    trainset = torchvision.datasets.CIFAR10('./data', train=True, download=True, transform=transform_train)\n",
    "    testset = torchvision.datasets.CIFAR10('./data', train=False, download=True, transform=transform_test)\n",
    "    return trainset, testset\n",
    "\n",
    "def inject_label_noise(labels, noise_rate, seed):\n",
    "    np.random.seed(seed)\n",
    "    labels = np.array(labels)\n",
    "    n_samples = len(labels)\n",
    "    n_noisy = int(noise_rate * n_samples)\n",
    "    noisy_idx = np.random.choice(n_samples, n_noisy, replace=False)\n",
    "    noisy_labels = labels.copy()\n",
    "    for idx in noisy_idx:\n",
    "        choices = [l for l in range(10) if l != labels[idx]]\n",
    "        noisy_labels[idx] = np.random.choice(choices)\n",
    "    return noisy_labels\n",
    "\n",
    "def get_data_loaders(trainset, testset):\n",
    "    train_loader = DataLoader(IndexedDataset(trainset), batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "    test_loader = DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                             shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Dual-Gradient Learning with Î» Schedule =====\n",
    "def train_dual_gradient_scheduled(model, train_loader, test_loader, clean_labels, noisy_labels, schedule):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 75], gamma=0.1)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    clean_labels_tensor = torch.tensor(clean_labels, device=device)\n",
    "    noisy_labels_tensor = torch.tensor(noisy_labels, device=device)\n",
    "    \n",
    "    cached_g_value = None\n",
    "    global_step = 0\n",
    "    \n",
    "    # è©³ç´°ãªå±¥æ­´ã‚’è¨˜éŒ²\n",
    "    history = {\n",
    "        'epoch': [],\n",
    "        'lambda': [],\n",
    "        'test_error': [],\n",
    "        'avg_cos': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        # ã‚¨ãƒãƒƒã‚¯ã”ã¨ã®Î»ã‚’å–å¾—\n",
    "        current_lambda = schedule.get_lambda(epoch)\n",
    "        \n",
    "        model.train()\n",
    "        epoch_cos = []\n",
    "        \n",
    "        for inputs, _, indices in train_loader:\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            indices = indices.to(device, non_blocking=True)\n",
    "            batch_noisy = noisy_labels_tensor[indices]\n",
    "            batch_clean = clean_labels_tensor[indices]\n",
    "            \n",
    "            # Structure gradient\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss_struct = criterion(outputs, batch_noisy)\n",
    "            loss_struct.backward(retain_graph=True)\n",
    "            g_struct = parameters_to_vector([p.grad for p in model.parameters()]).clone()\n",
    "            \n",
    "            # Value gradient\n",
    "            if global_step % K == 0 or cached_g_value is None:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss_value = criterion(outputs, batch_clean)\n",
    "                loss_value.backward()\n",
    "                cached_g_value = parameters_to_vector([p.grad for p in model.parameters()]).clone()\n",
    "            \n",
    "            # Mix gradients with current Î»\n",
    "            g_struct_norm = g_struct / (g_struct.norm() + 1e-12)\n",
    "            g_value_norm = cached_g_value / (cached_g_value.norm() + 1e-12)\n",
    "            \n",
    "            cos_sim = (g_struct_norm @ g_value_norm).item()\n",
    "            epoch_cos.append(cos_sim)\n",
    "            \n",
    "            g_mix = (1 - current_lambda) * g_struct_norm + current_lambda * g_value_norm\n",
    "            \n",
    "            # Apply mixed gradient\n",
    "            optimizer.zero_grad()\n",
    "            idx = 0\n",
    "            for p in model.parameters():\n",
    "                numel = p.numel()\n",
    "                p.grad = g_mix[idx:idx+numel].view(p.shape).clone()\n",
    "                idx += numel\n",
    "            optimizer.step()\n",
    "            global_step += 1\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        # æ¯ã‚¨ãƒãƒƒã‚¯è¨˜éŒ²ï¼ˆãƒ’ã‚¹ãƒ†ãƒªã‚·ã‚¹è§£æã®ãŸã‚ï¼‰\n",
    "        acc = evaluate(model, test_loader)\n",
    "        history['epoch'].append(epoch)\n",
    "        history['lambda'].append(current_lambda)\n",
    "        history['test_error'].append(1 - acc)\n",
    "        history['avg_cos'].append(np.mean(epoch_cos))\n",
    "    \n",
    "    final_acc = evaluate(model, test_loader)\n",
    "    \n",
    "    return final_acc, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ãƒ‡ãƒ¼ã‚¿æº–å‚™ =====\n",
    "trainset, testset = load_cifar10()\n",
    "clean_labels = np.array(trainset.targets)\n",
    "train_loader, test_loader = get_data_loaders(trainset, testset)\n",
    "\n",
    "print('Data prepared')\n",
    "\n",
    "# GPU warmup\n",
    "warmup_model = get_resnet18().to(device)\n",
    "for _ in range(20):\n",
    "    _ = warmup_model(torch.randn(BATCH_SIZE, 3, 32, 32, device=device))\n",
    "del warmup_model\n",
    "torch.cuda.empty_cache()\n",
    "print('GPU warmed up')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ãƒ¡ã‚¤ãƒ³å®Ÿé¨“ãƒ«ãƒ¼ãƒ— =====\n",
    "results = []\n",
    "checkpoint_file = f'{SAVE_DIR}/{EXP_NAME}_checkpoint.json'\n",
    "completed = set()\n",
    "\n",
    "if os.path.exists(checkpoint_file):\n",
    "    with open(checkpoint_file, 'r') as f:\n",
    "        results = json.load(f)\n",
    "    for r in results:\n",
    "        completed.add((r['schedule_type'], r['noise_rate'], r['seed']))\n",
    "    print(f'Checkpoint loaded: {len(results)} runs completed')\n",
    "\n",
    "total = len(experiments)\n",
    "\n",
    "for exp in experiments:\n",
    "    stype = exp['schedule_type']\n",
    "    eta = exp['noise_rate']\n",
    "    seed = exp['seed']\n",
    "    \n",
    "    if (stype, eta, seed) in completed:\n",
    "        continue\n",
    "    \n",
    "    run_num = len(completed) + 1\n",
    "    print(f'\\n[{run_num}/{total}] {stype} Î·={eta} seed={seed}')\n",
    "    \n",
    "    set_seed(seed)\n",
    "    noisy_labels = inject_label_noise(clean_labels, eta, seed)\n",
    "    \n",
    "    model = get_resnet18().to(device)\n",
    "    schedule = LambdaSchedule(stype, eta, EPOCHS)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    final_acc, history = train_dual_gradient_scheduled(\n",
    "        model, train_loader, test_loader, clean_labels, noisy_labels, schedule\n",
    "    )\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    result = {\n",
    "        'experiment_id': f'Q2-{run_num:03d}',\n",
    "        'experiment': EXP_NAME,\n",
    "        'schedule_type': stype,\n",
    "        'noise_rate': eta,\n",
    "        'seed': seed,\n",
    "        'final_acc': final_acc,\n",
    "        'final_error': 1 - final_acc,\n",
    "        'time_seconds': elapsed,\n",
    "        'history': history\n",
    "    }\n",
    "    results.append(result)\n",
    "    completed.add((stype, eta, seed))\n",
    "    \n",
    "    status = 'âœ…' if final_acc > 0.85 else ('âš ï¸ COLLAPSE' if final_acc < 0.5 else '')\n",
    "    print(f'  Final error: {1-final_acc:.4f} | Time: {elapsed/60:.1f} min {status}')\n",
    "    \n",
    "    with open(checkpoint_file, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "    remaining = total - run_num\n",
    "    eta_hours = remaining * elapsed / 3600\n",
    "    print(f'  Progress: {run_num}/{total} | ETA: {eta_hours:.1f} hours')\n",
    "    \n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print('\\n' + '='*70)\n",
    "print('ALL EXPERIMENTS COMPLETED!')\n",
    "print('='*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== çµæœä¿å­˜ =====\n",
    "import pandas as pd\n",
    "\n",
    "with open(f'{SAVE_DIR}/{EXP_NAME}_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "results_flat = [{k: v for k, v in r.items() if k != 'history'} for r in results]\n",
    "df = pd.DataFrame(results_flat)\n",
    "df.to_csv(f'{SAVE_DIR}/{EXP_NAME}_results.csv', index=False)\n",
    "\n",
    "print(f'Results saved to {SAVE_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ãƒ’ã‚¹ãƒ†ãƒªã‚·ã‚¹åˆ†æ =====\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('='*70)\n",
    "print('HYSTERESIS ANALYSIS')\n",
    "print('='*70)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "schedule_colors = {\n",
    "    'fixed_ordered': '#2ecc71',\n",
    "    'fixed_collapse': '#e74c3c',\n",
    "    'quench_to_collapse': '#9b59b6',\n",
    "    'quench_to_ordered': '#3498db',\n",
    "    'ramp_up': '#f39c12',\n",
    "    'ramp_down': '#1abc9c'\n",
    "}\n",
    "\n",
    "for i, eta in enumerate([0.4, 0.8]):\n",
    "    # Left: Learning curves\n",
    "    ax = axes[i, 0]\n",
    "    for stype in SCHEDULE_TYPES:\n",
    "        # ä»£è¡¨çš„ãªseed=0ã®æ›²ç·šã‚’æç”»\n",
    "        for r in results:\n",
    "            if r['schedule_type'] == stype and r['noise_rate'] == eta and r['seed'] == 0:\n",
    "                history = r['history']\n",
    "                ax.plot(history['epoch'], history['test_error'],\n",
    "                       color=schedule_colors[stype], label=stype, linewidth=1.5, alpha=0.8)\n",
    "                break\n",
    "    \n",
    "    ax.axvline(x=30, color='gray', linestyle='--', alpha=0.5, label='Quench point')\n",
    "    ax.set_xlabel('Epoch', fontsize=12)\n",
    "    ax.set_ylabel('Test Error', fontsize=12)\n",
    "    ax.set_title(f'Î·={eta}: Learning Curves by Schedule', fontsize=12)\n",
    "    ax.legend(loc='upper right', fontsize=8)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Right: Final error comparison\n",
    "    ax = axes[i, 1]\n",
    "    df_eta = df[df['noise_rate'] == eta]\n",
    "    df_agg = df_eta.groupby('schedule_type')['final_error'].agg(['mean', 'std']).reset_index()\n",
    "    \n",
    "    x_pos = range(len(df_agg))\n",
    "    bars = ax.bar(x_pos, df_agg['mean'], yerr=df_agg['std'], capsize=4,\n",
    "                  color=[schedule_colors.get(s, 'gray') for s in df_agg['schedule_type']])\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(df_agg['schedule_type'], rotation=45, ha='right', fontsize=9)\n",
    "    ax.set_ylabel('Final Error', fontsize=12)\n",
    "    ax.set_title(f'Î·={eta}: Final Error by Schedule', fontsize=12)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{SAVE_DIR}/figures/{EXP_NAME}_hysteresis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ãƒ’ã‚¹ãƒ†ãƒªã‚·ã‚¹åˆ¤å®š\n",
    "print('\\n--- Hysteresis Detection ---')\n",
    "for eta in [0.4, 0.8]:\n",
    "    print(f'\\nÎ·={eta}:')\n",
    "    df_eta = df[df['noise_rate'] == eta]\n",
    "    \n",
    "    # fixed_orderedã¨fixed_collapseã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³\n",
    "    baseline_ordered = df_eta[df_eta['schedule_type'] == 'fixed_ordered']['final_error'].mean()\n",
    "    baseline_collapse = df_eta[df_eta['schedule_type'] == 'fixed_collapse']['final_error'].mean()\n",
    "    \n",
    "    print(f'  Baselines: ordered={baseline_ordered:.4f}, collapse={baseline_collapse:.4f}')\n",
    "    \n",
    "    # ã‚¯ã‚¨ãƒ³ãƒå¾Œã®æœ€çµ‚çŠ¶æ…‹\n",
    "    quench_to_collapse = df_eta[df_eta['schedule_type'] == 'quench_to_collapse']['final_error'].mean()\n",
    "    quench_to_ordered = df_eta[df_eta['schedule_type'] == 'quench_to_ordered']['final_error'].mean()\n",
    "    \n",
    "    print(f'  Quench to collapse: {quench_to_collapse:.4f} (expect ~{baseline_collapse:.4f})')\n",
    "    print(f'  Quench to ordered: {quench_to_ordered:.4f} (expect ~{baseline_ordered:.4f})')\n",
    "    \n",
    "    # ãƒ’ã‚¹ãƒ†ãƒªã‚·ã‚¹åˆ¤å®š\n",
    "    hysteresis_collapse = abs(quench_to_collapse - baseline_collapse)\n",
    "    hysteresis_ordered = abs(quench_to_ordered - baseline_ordered)\n",
    "    \n",
    "    if hysteresis_collapse > 0.05 or hysteresis_ordered > 0.05:\n",
    "        print(f'  âš¡ HYSTERESIS DETECTED! Gaps: {hysteresis_collapse:.4f}, {hysteresis_ordered:.4f}')\n",
    "    else:\n",
    "        print(f'  âœ… No significant hysteresis (gaps: {hysteresis_collapse:.4f}, {hysteresis_ordered:.4f})')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
