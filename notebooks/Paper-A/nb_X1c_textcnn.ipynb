{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# X1c: TextCNN (No Pretrained) \u2014 Phase Structure Discovery (NLP)\n\n**Paper-A (P0009) \u2014 X Series: Cross-Domain Generality**\n\n| Item | Value |\n|------|-------|\n| Dataset | SST-2 (binary sentiment) |\n| Model | **TextCNN** (random init, no pretrained weights) |\n| Noise | Symmetric, \u03b7 = 0.4 |\n| Trusted ratio | 5% |\n| \u03bb grid | {0.10, 0.20, 0.30, 0.40, 0.50, 0.60} |\n| Seeds | 0\u201319 (n=20 per \u03bb) |\n| Total runs | **120** |\n| Estimated time | ~30\u201360 min (GPU) |\n\n**Rationale**: DistilBERT's pretrained weights act as a buffer that prevents phase transitions. \nTextCNN with random initialization matches the Vision experiments (ResNet from scratch) \nand should be more susceptible to \u03bb-induced bifurcation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install -q datasets\n\nimport os\nimport json\nimport time\nimport random\nimport warnings\nimport logging\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom datasets import load_dataset\nfrom collections import Counter\n\nwarnings.filterwarnings(\"ignore\")\nos.environ[\"TRANSFORMERS_VERBOSITY\"] = \"error\"\n\nprint(f\"PyTorch: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "CONFIG = {\n    \"experiment\": \"exp_X1c_textcnn\",\n    \"series\": \"X\",\n    \"dataset\": \"SST-2\",\n    \"num_classes\": 2,\n    \"model_name\": \"TextCNN\",\n\n    \"noise_type\": \"symmetric\",\n    \"noise_rate\": 0.4,\n    \"trusted_ratio\": 0.05,\n\n    \"lambda_values\": [0.10, 0.20, 0.30, 0.40, 0.50, 0.60],\n    \"seeds\": list(range(20)),\n\n    # Training (longer than BERT fine-tuning since training from scratch)\n    \"epochs\": 20,\n    \"batch_size\": 128,\n    \"learning_rate\": 1e-3,\n    \"weight_decay\": 1e-4,\n    \"max_seq_length\": 64,       # shorter for CNN\n    \"max_vocab_size\": 25000,\n    \"embed_dim\": 128,\n    \"num_filters\": 100,\n    \"filter_sizes\": [3, 4, 5],\n    \"dropout\": 0.5,\n\n    \"use_bf16\": True,\n    \"max_train_samples\": 16000,\n    \"csv_measure_every_n_steps\": 10,\n\n    \"output_dir\": \"X1c_results\",\n}\n\nos.makedirs(CONFIG[\"output_dir\"], exist_ok=True)\n\nn_runs = len(CONFIG[\"lambda_values\"]) * len(CONFIG[\"seeds\"])\nn_used = min(int(67349 * 0.95), CONFIG[\"max_train_samples\"])\nsteps_per_epoch = n_used // CONFIG[\"batch_size\"]\ntotal_steps = steps_per_epoch * CONFIG[\"epochs\"]\nest_per_run = total_steps * 5 / 1000 + 5  # ~5ms/step for CNN\n\nprint(f\"Total runs: {n_runs}\")\nprint(f\"Steps/epoch: ~{steps_per_epoch}, Total steps/run: ~{total_steps}\")\nprint(f\"Est. time/run: ~{est_per_run:.0f}s\")\nprint(f\"Est. total: ~{n_runs * est_per_run / 60:.0f} min\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Google Drive Mount"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from google.colab import drive\ndrive.mount('/content/drive')\n\nDRIVE_BASE = \"/content/drive/MyDrive/Paper-A_X_series\"\nDRIVE_OUTPUT = f\"{DRIVE_BASE}/exp_X1c_textcnn\"\nos.makedirs(DRIVE_OUTPUT, exist_ok=True)\nLOCAL_OUTPUT = CONFIG[\"output_dir\"]\nos.makedirs(LOCAL_OUTPUT, exist_ok=True)\n\ndef save_to_drive(filename, data):\n    local_path = os.path.join(LOCAL_OUTPUT, filename)\n    with open(local_path, \"w\") as f:\n        json.dump(data, f, indent=2)\n    drive_path = os.path.join(DRIVE_OUTPUT, filename)\n    with open(drive_path, \"w\") as f:\n        json.dump(data, f, indent=2)\n    return drive_path\n\ndef save_figure_to_drive(fig, filename, dpi=300):\n    for d in [LOCAL_OUTPUT, DRIVE_OUTPUT]:\n        fig.savefig(os.path.join(d, filename), dpi=dpi, bbox_inches=\"tight\", facecolor=\"white\")\n\nprint(f\"Drive: {DRIVE_OUTPUT}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Deterministic Seeding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Data Preparation (Manual Tokenization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Loading SST-2...\")\nraw_dataset = load_dataset(\"glue\", \"sst2\")\n\ntrain_texts = list(raw_dataset[\"train\"][\"sentence\"])\ntrain_labels = list(raw_dataset[\"train\"][\"label\"])\ntest_texts = list(raw_dataset[\"validation\"][\"sentence\"])\ntest_labels = list(raw_dataset[\"validation\"][\"label\"])\n\nprint(f\"Train: {len(train_texts)}, Test: {len(test_texts)}\")\n\n# --- Build vocabulary ---\ndef simple_tokenize(text):\n    return text.lower().split()\n\nword_counts = Counter()\nfor text in train_texts:\n    word_counts.update(simple_tokenize(text))\n\n# Special tokens\nPAD_IDX = 0\nUNK_IDX = 1\nvocab = {\"<PAD>\": PAD_IDX, \"<UNK>\": UNK_IDX}\nfor word, count in word_counts.most_common(CONFIG[\"max_vocab_size\"] - 2):\n    vocab[word] = len(vocab)\n\nprint(f\"Vocabulary size: {len(vocab)}\")\n\n# --- Encode texts ---\ndef encode_text(text, max_len):\n    tokens = simple_tokenize(text)[:max_len]\n    ids = [vocab.get(t, UNK_IDX) for t in tokens]\n    # Pad\n    ids = ids + [PAD_IDX] * (max_len - len(ids))\n    return ids\n\nmax_len = CONFIG[\"max_seq_length\"]\ntrain_encoded = torch.tensor([encode_text(t, max_len) for t in train_texts], dtype=torch.long)\ntest_encoded = torch.tensor([encode_text(t, max_len) for t in test_texts], dtype=torch.long)\ntrain_labels_tensor = torch.tensor(train_labels, dtype=torch.long)\ntest_labels_tensor = torch.tensor(test_labels, dtype=torch.long)\n\nprint(f\"Train tensor: {train_encoded.shape}, Test tensor: {test_encoded.shape}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class SimpleTextDataset(Dataset):\n    def __init__(self, input_ids, labels):\n        self.input_ids = input_ids\n        self.labels = labels\n    def __len__(self):\n        return len(self.labels)\n    def __getitem__(self, idx):\n        return {\"input_ids\": self.input_ids[idx], \"labels\": self.labels[idx]}\n\ntest_dataset = SimpleTextDataset(test_encoded, test_labels_tensor)\ntest_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\nprint(f\"Test loader: {len(test_dataset)} samples\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Noise Injection & Trusted Subset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def prepare_noisy_and_trusted(labels, noise_rate, trusted_ratio,\n                              num_classes, seed, max_noisy_samples=None):\n    rng = np.random.RandomState(seed + 10000)\n    n = len(labels)\n    labels_arr = np.array(labels)\n    indices = np.arange(n)\n\n    # Stratified trusted subset\n    trusted_indices = []\n    for c in range(num_classes):\n        class_idx = indices[labels_arr == c]\n        n_sel = max(1, int(len(class_idx) * trusted_ratio))\n        trusted_indices.extend(rng.choice(class_idx, size=n_sel, replace=False))\n    trusted_indices = np.array(sorted(trusted_indices))\n\n    noisy_mask = np.ones(n, dtype=bool)\n    noisy_mask[trusted_indices] = False\n    noisy_indices = indices[noisy_mask]\n\n    # Inject noise\n    noisy_labels = labels_arr.copy()\n    n_flip = int(len(noisy_indices) * noise_rate)\n    flip_idx = rng.choice(noisy_indices, size=n_flip, replace=False)\n    for idx in flip_idx:\n        candidates = [c for c in range(num_classes) if c != noisy_labels[idx]]\n        noisy_labels[idx] = rng.choice(candidates)\n\n    # Subsample\n    if max_noisy_samples and len(noisy_indices) > max_noisy_samples:\n        noisy_indices = np.sort(rng.choice(noisy_indices, size=max_noisy_samples, replace=False))\n\n    actual_noise = np.mean(noisy_labels[noisy_indices] != labels_arr[noisy_indices])\n    print(f\"  Trusted: {len(trusted_indices)} | Noisy: {len(noisy_indices)} (\u03b7_actual={actual_noise:.3f})\")\n    return torch.tensor(noisy_labels, dtype=torch.long), trusted_indices, noisy_indices\n\nprint(\"Testing...\")\n_, ti, ni = prepare_noisy_and_trusted(train_labels, 0.4, 0.05, 2, 0, 16000)\nprint(f\"  OK: {len(ti)} + {len(ni)}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. TextCNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class TextCNN(nn.Module):\n    def __init__(self, vocab_size, embed_dim, num_classes, num_filters,\n                 filter_sizes, dropout=0.5):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n        self.convs = nn.ModuleList([\n            nn.Conv1d(embed_dim, num_filters, fs) for fs in filter_sizes\n        ])\n        self.dropout = nn.Dropout(dropout)\n        self.fc = nn.Linear(num_filters * len(filter_sizes), num_classes)\n\n    def forward(self, input_ids, labels=None):\n        # input_ids: (B, L)\n        x = self.embedding(input_ids)          # (B, L, E)\n        x = x.transpose(1, 2)                  # (B, E, L)\n        pooled = []\n        for conv in self.convs:\n            h = F.relu(conv(x))                # (B, F, L-fs+1)\n            h = F.max_pool1d(h, h.size(2)).squeeze(2)  # (B, F)\n            pooled.append(h)\n        cat = torch.cat(pooled, dim=1)         # (B, F*len(filter_sizes))\n        cat = self.dropout(cat)\n        logits = self.fc(cat)                  # (B, C)\n\n        loss = None\n        if labels is not None:\n            loss = F.cross_entropy(logits, labels)\n        return type('Output', (), {'loss': loss, 'logits': logits})()\n\ndef create_model(config, vocab_size):\n    return TextCNN(\n        vocab_size=vocab_size,\n        embed_dim=config[\"embed_dim\"],\n        num_classes=config[\"num_classes\"],\n        num_filters=config[\"num_filters\"],\n        filter_sizes=config[\"filter_sizes\"],\n        dropout=config[\"dropout\"]\n    )\n\n# Test\nm = create_model(CONFIG, len(vocab))\nprint(f\"TextCNN params: {sum(p.numel() for p in m.parameters()):,}\")\ndel m\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Dual-Gradient Core"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def get_head_param_names(model):\n    return [n for n, _ in model.named_parameters() if \"fc\" in n]\n\ndef extract_grads(model):\n    return {n: p.grad.clone() for n, p in model.named_parameters() if p.grad is not None}\n\ndef normalize_grad_dict(grads):\n    flat = torch.cat([g.flatten() for g in grads.values()])\n    norm = flat.norm()\n    if norm > 0:\n        return {n: g / norm for n, g in grads.items()}, norm.item()\n    return grads, 0.0\n\ndef cosine_sim(grads_a, grads_b, param_names=None):\n    if param_names:\n        keys = [n for n in param_names if n in grads_a and n in grads_b]\n    else:\n        keys = sorted(set(grads_a) & set(grads_b))\n    if not keys:\n        return 0.0\n    va = torch.cat([grads_a[n].flatten() for n in keys])\n    vb = torch.cat([grads_b[n].flatten() for n in keys])\n    return F.cosine_similarity(va.unsqueeze(0), vb.unsqueeze(0)).item()\n\ndef set_mixed_grad(model, g_struct_n, g_value_n, lam):\n    for n, p in model.named_parameters():\n        if n in g_struct_n and n in g_value_n:\n            p.grad = (1 - lam) * g_struct_n[n] + lam * g_value_n[n]\n        elif n in g_struct_n:\n            p.grad = (1 - lam) * g_struct_n[n]\n        elif n in g_value_n:\n            p.grad = lam * g_value_n[n]\n\n@torch.no_grad()\ndef evaluate(model, test_loader, device):\n    model.eval()\n    correct = total = 0\n    total_loss = 0.0\n    n = 0\n    for batch in test_loader:\n        ids = batch[\"input_ids\"].to(device)\n        labels = batch[\"labels\"].to(device)\n        out = model(input_ids=ids, labels=labels)\n        preds = out.logits.argmax(dim=-1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n        total_loss += out.loss.item()\n        n += 1\n    model.train()\n    acc = correct / total\n    return acc, 1.0 - acc, total_loss / n\n\nprint(\"Core functions defined.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Single Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def run_single_experiment(lam, seed, config):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    set_seed(seed)\n    t_start = time.time()\n\n    noisy_labels, trusted_idx, noisy_idx = prepare_noisy_and_trusted(\n        train_labels, config[\"noise_rate\"], config[\"trusted_ratio\"],\n        config[\"num_classes\"], seed, config.get(\"max_train_samples\")\n    )\n\n    noisy_ds = SimpleTextDataset(train_encoded[noisy_idx], noisy_labels[noisy_idx])\n    trusted_ds = SimpleTextDataset(train_encoded[trusted_idx], noisy_labels[trusted_idx])\n\n    struct_loader = DataLoader(noisy_ds, batch_size=config[\"batch_size\"], shuffle=True, drop_last=True)\n    value_loader = DataLoader(trusted_ds, batch_size=min(config[\"batch_size\"], len(trusted_ds)),\n                              shuffle=True, drop_last=False)\n\n    set_seed(seed)\n    model = create_model(config, len(vocab)).to(device)\n    model.train()\n    head_params = get_head_param_names(model)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"learning_rate\"],\n                                 weight_decay=config[\"weight_decay\"])\n\n    use_amp = config.get(\"use_bf16\", False) and device.type == \"cuda\"\n    amp_dtype = torch.bfloat16 if use_amp else torch.float32\n\n    epoch_logs = []\n    all_csv = []\n    measure_every = config.get(\"csv_measure_every_n_steps\", 10)\n    global_step = 0\n\n    for epoch in range(config[\"epochs\"]):\n        epoch_loss_s = epoch_loss_v = 0.0\n        epoch_csv = []\n        n_steps = 0\n        value_iter = iter(value_loader)\n\n        for struct_batch in struct_loader:\n            optimizer.zero_grad()\n            s_ids = struct_batch[\"input_ids\"].to(device)\n            s_labels = struct_batch[\"labels\"].to(device)\n            with torch.amp.autocast(\"cuda\", dtype=amp_dtype, enabled=use_amp):\n                out_s = model(input_ids=s_ids, labels=s_labels)\n            out_s.loss.backward()\n            g_struct = extract_grads(model)\n\n            optimizer.zero_grad()\n            try:\n                vb = next(value_iter)\n            except StopIteration:\n                value_iter = iter(value_loader)\n                vb = next(value_iter)\n            v_ids = vb[\"input_ids\"].to(device)\n            v_labels = vb[\"labels\"].to(device)\n            with torch.amp.autocast(\"cuda\", dtype=amp_dtype, enabled=use_amp):\n                out_v = model(input_ids=v_ids, labels=v_labels)\n            out_v.loss.backward()\n            g_value = extract_grads(model)\n\n            g_sn, _ = normalize_grad_dict(g_struct)\n            g_vn, _ = normalize_grad_dict(g_value)\n            set_mixed_grad(model, g_sn, g_vn, lam)\n            optimizer.step()\n\n            global_step += 1\n            n_steps += 1\n            epoch_loss_s += out_s.loss.item()\n            epoch_loss_v += out_v.loss.item()\n\n            if global_step % measure_every == 0:\n                c = cosine_sim(g_struct, g_value, head_params)\n                epoch_csv.append(c)\n                all_csv.append(c)\n\n        test_acc, test_error, test_loss = evaluate(model, test_loader, device)\n        mean_csv = float(np.mean(epoch_csv)) if epoch_csv else 0.0\n\n        epoch_log = {\n            \"epoch\": epoch + 1, \"steps\": n_steps,\n            \"test_acc\": round(test_acc, 4), \"test_error\": round(test_error, 4),\n            \"test_loss\": round(test_loss, 4),\n            \"loss_struct\": round(epoch_loss_s / max(n_steps, 1), 4),\n            \"loss_value\": round(epoch_loss_v / max(n_steps, 1), 4),\n            \"c_sv_head\": round(mean_csv, 4),\n        }\n        epoch_logs.append(epoch_log)\n\n        if (epoch + 1) % 5 == 0 or epoch == 0:\n            print(f\"    Ep {epoch+1}/{config['epochs']}: err={test_error:.4f} acc={test_acc:.4f} c_sv={mean_csv:.4f}\")\n\n    final_acc, final_error, _ = evaluate(model, test_loader, device)\n    elapsed = time.time() - t_start\n\n    result = {\n        \"experiment_id\": f\"X1c-{seed:03d}-lam{lam:.2f}\",\n        \"experiment\": config[\"experiment\"],\n        \"dataset\": config[\"dataset\"],\n        \"model\": config[\"model_name\"],\n        \"noise_type\": config[\"noise_type\"],\n        \"noise_rate\": config[\"noise_rate\"],\n        \"trusted_ratio\": config[\"trusted_ratio\"],\n        \"lambda\": lam,\n        \"seed\": seed,\n        \"test_acc\": round(final_acc, 4),\n        \"test_error\": round(final_error, 4),\n        \"best_acc\": round(max(l[\"test_acc\"] for l in epoch_logs), 4),\n        \"best_error\": round(min(l[\"test_error\"] for l in epoch_logs), 4),\n        \"avg_cos_struct_value\": round(float(np.mean(all_csv)) if all_csv else 0.0, 4),\n        \"total_steps\": global_step,\n        \"epochs\": config[\"epochs\"],\n        \"epoch_logs\": epoch_logs,\n        \"time_seconds\": round(elapsed, 1),\n    }\n    del model, optimizer\n    torch.cuda.empty_cache()\n    return result\n\nprint(\"Single run function defined (TextCNN).\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Main Execution Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "all_results = []\ntotal_runs = len(CONFIG[\"lambda_values\"]) * len(CONFIG[\"seeds\"])\nrun_idx = 0\nt_total_start = time.time()\n\nprint(\"=\" * 70)\nprint(f\"X1c: TextCNN Coarse \u03bb Sweep \u2014 {total_runs} runs\")\nprint(f\"  \u03bb: {CONFIG['lambda_values']}, \u03b7={CONFIG['noise_rate']}\")\nprint(\"=\" * 70)\n\nfor lam in CONFIG[\"lambda_values\"]:\n    print(f\"\\n{'='*55}  \u03bb = {lam:.2f}  {'='*10}\")\n    lambda_results = []\n\n    for seed in CONFIG[\"seeds\"]:\n        run_idx += 1\n        print(f\"  Run {run_idx}/{total_runs}: \u03bb={lam:.2f} seed={seed}\")\n        result = run_single_experiment(lam, seed, CONFIG)\n        lambda_results.append(result)\n        all_results.append(result)\n\n        elapsed = time.time() - t_total_start\n        eta = elapsed / run_idx * (total_runs - run_idx)\n        print(f\"    \u2192 err={result['test_error']:.4f} c_sv={result['avg_cos_struct_value']:.4f} \"\n              f\"{result['time_seconds']:.0f}s [ETA: {eta/60:.0f}m]\")\n\n    errors = [r[\"test_error\"] for r in lambda_results]\n    print(f\"  \u03bb={lam:.2f}: mean={np.mean(errors):.4f} \u00b1 {np.std(errors):.4f}\")\n    save_to_drive(f\"X1c_lambda{lam:.2f}_results.json\", lambda_results)\n    print(f\"  Saved \u2192 Drive \u2713\")\n\nt_total = time.time() - t_total_start\nsave_to_drive(\"X1c_results.json\", all_results)\nsave_to_drive(\"X1c_config.json\", CONFIG)\nprint(f\"\\n{'='*70}\")\nprint(f\"COMPLETE: {total_runs} runs in {t_total/60:.1f} min\")\nprint(f\"Results: {DRIVE_OUTPUT}\")\nprint(f\"{'='*70}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Analysis & Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\nfrom scipy import stats\n\n# Load\nlocal_path = os.path.join(LOCAL_OUTPUT, \"X1c_results.json\")\ndrive_path = os.path.join(DRIVE_OUTPUT, \"X1c_results.json\")\npath = local_path if os.path.exists(local_path) else drive_path\nwith open(path) as f:\n    results = json.load(f)\n\nlambda_data = {}\nfor r in results:\n    lam = r[\"lambda\"]\n    if lam not in lambda_data:\n        lambda_data[lam] = {\"errors\": [], \"cos\": []}\n    lambda_data[lam][\"errors\"].append(r[\"test_error\"])\n    lambda_data[lam][\"cos\"].append(r[\"avg_cos_struct_value\"])\n\nlambdas = sorted(lambda_data.keys())\n\n# --- Summary table ---\nprint(f\"{'\u03bb':>6} | {'mean_err':>10} | {'std_err':>10} | {'min':>8} | {'max':>8} | {'var':>10} | {'c_sv':>8}\")\nprint(\"-\"*70)\nfor lam in lambdas:\n    e = lambda_data[lam][\"errors\"]\n    c = lambda_data[lam][\"cos\"]\n    print(f\"{lam:>6.2f} | {np.mean(e):>10.4f} | {np.std(e):>10.4f} | \"\n          f\"{np.min(e):>8.4f} | {np.max(e):>8.4f} | {np.var(e):>10.6f} | {np.mean(c):>8.4f}\")\n\n# --- Bimodality check ---\nprint(\"\\n=== S1 CHECK ===\")\nfor lam in lambdas:\n    e = np.array(lambda_data[lam][\"errors\"])\n    stat, p = stats.shapiro(e)\n    cv = np.std(e) / np.mean(e)\n    rng = np.max(e) - np.min(e)\n    flag = \" \u2691\" if (cv > 0.15 or p < 0.05 or rng > 0.15) else \"\"\n    print(f\"  \u03bb={lam:.2f}: CV={cv:.3f} range={rng:.4f} Shapiro_p={p:.4f}{flag}\")\n\n# --- Plot ---\nfig, axes = plt.subplots(1, 3, figsize=(18, 5))\n\nax = axes[0]\nfor i, lam in enumerate(lambdas):\n    jitter = np.random.normal(0, 0.06, len(lambda_data[lam][\"errors\"]))\n    ax.scatter([i+j for j in jitter], lambda_data[lam][\"errors\"], alpha=0.6, s=25)\nbp = ax.boxplot([lambda_data[l][\"errors\"] for l in lambdas],\n                positions=range(len(lambdas)), widths=0.5, patch_artist=True)\nfor p in bp[\"boxes\"]: p.set_facecolor(\"#1F77B4\"); p.set_alpha(0.3)\nax.set_xticks(range(len(lambdas)))\nax.set_xticklabels([f\"{l:.2f}\" for l in lambdas])\nax.set_xlabel(\"\u03bb\"); ax.set_ylabel(\"Test Error\")\nax.set_title(\"(a) Error Distribution\"); ax.grid(True, alpha=0.3)\n\nax = axes[1]\nvariances = [np.var(lambda_data[l][\"errors\"]) for l in lambdas]\nax.bar(range(len(lambdas)), [v*10000 for v in variances], color=\"#FF7F0E\", edgecolor=\"black\")\nax.set_xticks(range(len(lambdas)))\nax.set_xticklabels([f\"{l:.2f}\" for l in lambdas])\nax.set_xlabel(\"\u03bb\"); ax.set_ylabel(\"Variance (\u00d710\u2074)\")\nax.set_title(\"(b) Variance\"); ax.grid(True, alpha=0.3)\n\nax = axes[2]\nmeans_c = [np.mean(lambda_data[l][\"cos\"]) for l in lambdas]\nstds_c = [np.std(lambda_data[l][\"cos\"]) for l in lambdas]\nax.errorbar(lambdas, means_c, yerr=stds_c, fmt='s-', color=\"#2CA02C\", capsize=5)\nax.axhline(0, color=\"gray\", ls=\"--\", alpha=0.5)\nax.set_xlabel(\"\u03bb\"); ax.set_ylabel(\"c_sv (head)\")\nax.set_title(\"(c) Gradient Geometry\"); ax.grid(True, alpha=0.3)\n\nfig.suptitle(\"X1c: TextCNN (No Pretrained) \u2014 SST-2, \u03b7=0.4\", fontsize=14, fontweight=\"bold\", y=1.02)\nplt.tight_layout()\nsave_figure_to_drive(fig, \"X1c_phase_structure.png\")\nplt.show()\nprint(\"Done.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"Results saved to: {DRIVE_OUTPUT}\")\nfor f in sorted(os.listdir(DRIVE_OUTPUT)):\n    sz = os.path.getsize(os.path.join(DRIVE_OUTPUT, f))\n    print(f\"  {f}  ({sz/1024:.1f} KB)\")\n\nimport shutil\nshutil.make_archive(\"X1c_results\", \"zip\", LOCAL_OUTPUT)\ntry:\n    from google.colab import files\n    files.download(\"X1c_results.zip\")\nexcept: pass\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}